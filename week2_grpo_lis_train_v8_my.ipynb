{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2565228",
   "metadata": {},
   "source": [
    "# ДЗ Неделя 2 — GRPO обучение (TRAIN)\n",
    "\n",
    "Этот ноутбук предназначен **только для обучения** (Unsloth + TRL/GRPO) и сохранения обученной модели.\n",
    "\n",
    "Что вы получите на выходе:\n",
    "- `models/<cfg.merged_model_subdir>/` — **merged** веса (base + LoRA), готовые для vLLM/transformers\n",
    "- `results/trained_model.json` — путь к merged‑модели\n",
    "- `data/test_*.jsonl` и `data/dev_*.jsonl` — фиксированные наборы задач (не пересэмпливаются)\n",
    "\n",
    "Для подсчёта метрик **до/после** обучения используйте отдельный ноутбук:\n",
    "`week2_grpo_lis_infer_eval.ipynb` (желательно в **отдельной среде** с `vLLM`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb2f1b",
   "metadata": {},
   "source": [
    "## Важно про `torch.compile` / Unsloth\n",
    "\n",
    "Если во время обучения вы видите ошибку вида `FailOnRecompileLimitHit: recompile_limit reached with fullgraph=True`,\n",
    "это значит, что `torch.compile` слишком часто перекомпилирует граф (обычно из‑за разных длин последовательностей).\n",
    "\n",
    "В этом ноутбуке есть 2 рычага в `ExperimentConfig`:\n",
    "- `unsloth_compile_disable=True` — полностью отключить auto‑compiler в Unsloth (стабильнее, но медленнее).\n",
    "- `torchdynamo_cache_size_limit` / `torchdynamo_accumulated_cache_size_limit` — увеличить лимиты кеша TorchDynamo,\n",
    "  чтобы fullgraph‑компиляция не падала.\n",
    "\n",
    "**Если вы меняете `unsloth_compile_disable`, лучше сделать Restart Kernel и запустить ноутбук заново**, чтобы флаг\n",
    "успел примениться до импорта `unsloth`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2396b0",
   "metadata": {},
   "source": [
    "## 0. Подготовка окружения\n",
    "\n",
    "Если запускаете в **Google Colab** / **Kaggle**, включите GPU:\n",
    "\n",
    "- Colab: *Runtime → Change runtime type → GPU*\n",
    "- Kaggle: *Settings → Accelerator → GPU*\n",
    "\n",
    "Затем выполните ячейку с установкой зависимостей ниже.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f20d7",
   "metadata": {},
   "source": [
    "### 0.1 Конфигурация эксперимента (одна точка правды)\n",
    "\n",
    "Чтобы затем **без боли перенести код в репозиторий**, держим все важные параметры (модель, датасеты, GRPO, пути, seed) в одном объекте `cfg`.\n",
    "\n",
    "Дальше по ноутбуку мы стараемся **не использовать “магические числа”**, а брать значения из `cfg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf55c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from typing import Optional, List, Dict, Any, Iterable\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конфиг сохранён в: results/config.json\n",
      "DATA_DIR    = /home/yaros/DS-Mag/AI-SelectedTopics/W2-1/data\n",
      "RESULTS_DIR = /home/yaros/DS-Mag/AI-SelectedTopics/W2-1/results\n",
      "MODELS_DIR  = /home/yaros/DS-Mag/AI-SelectedTopics/W2-1/models\n",
      "Эффективный batch (prompts/step) = 8  (bs=1 * accum=8)\n",
      "num_generations (G) = 8  -> completions/step ~ 64\n"
     ]
    }
   ],
   "source": [
    "# --- Конфиг эксперимента ---\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pathlib import Path\n",
    "import json, random\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    # ====== Модель ======\n",
    "    base_model: str = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "    # ====== Воспроизводимость ======\n",
    "    global_seed: int = 42\n",
    "\n",
    "    # ====== Пути ======\n",
    "    data_dir: str = \"data\"\n",
    "    results_dir: str = \"results\"\n",
    "    models_dir: str = \"models\"\n",
    "\n",
    "    # ====== Эксперимент‑трекинг (Comet ML) ======\n",
    "    comet_enabled: bool = True\n",
    "    comet_project_name: str = \"ds-mag-w2-grpo\"\n",
    "    comet_workspace: Optional[str] = None\n",
    "    comet_offline: bool = False\n",
    "    comet_tags: List[str] = field(default_factory=lambda: [\"W2\", \"GRPO\", \"LIS\"])\n",
    "\n",
    "    # ====== Фиксированные тестовые наборы (для финальной оценки в eval-env) ======\n",
    "    recreate_tests: bool = False\n",
    "    test_specs: List[Dict[str, Any]] = field(default_factory=lambda: [\n",
    "        {\"name\": \"easy\",   \"difficulty\": 2, \"n\": 200, \"seed\": 1001},\n",
    "        {\"name\": \"medium\", \"difficulty\": 5, \"n\": 200, \"seed\": 2001},\n",
    "        {\"name\": \"hard\",   \"difficulty\": 8, \"n\": 200, \"seed\": 3001},\n",
    "    ])\n",
    "\n",
    "    # ====== Dev-наборы (валидация во время RL) ======\n",
    "    # Делаем НЕ один dev, а 3 \"среза\" по сложности, чтобы видеть:\n",
    "    # - не забываем ли простые примеры,\n",
    "    # - растём ли на сложных.\n",
    "    recreate_dev: bool = False\n",
    "    dev_specs: List[Dict[str, Any]] = field(default_factory=lambda: [\n",
    "        {\"name\": \"easy\",   \"difficulty\": 2, \"n\": 128, \"seed\": 4001},\n",
    "        {\"name\": \"medium\", \"difficulty\": 5, \"n\": 128, \"seed\": 4002},\n",
    "        {\"name\": \"hard\",   \"difficulty\": 8, \"n\": 128, \"seed\": 4003},\n",
    "    ])\n",
    "\n",
    "    # Быстрый dev‑eval: на каждом прогоне берём поднабор (по каждому devset)\n",
    "    dev_eval_n: int = 32\n",
    "    dev_eval_every_steps: int = 50\n",
    "\n",
    "    # Параметры генерации в dev-eval\n",
    "    dev_max_new_tokens: int = 64\n",
    "    dev_temperature: float = 0.0  # 0 -> greedy\n",
    "    dev_full_eval_on_best: bool = True\n",
    "\n",
    "    # Каким dev‑метриком выбираем \"best checkpoint\"\n",
    "    # Важно: сравниваем correctness/dev accuracy, а не \"reward\".\n",
    "    best_metric: str = \"dev/avg\"  # варианты: \"dev/avg\", \"dev/hard\", \"dev/medium\", \"dev/easy\"\n",
    "    dev_metric_weights: Dict[str, float] = field(default_factory=lambda: {\n",
    "        \"easy\": 0.25,\n",
    "        \"medium\": 0.25,\n",
    "        \"hard\": 0.50,\n",
    "    })\n",
    "    best_min_delta: float = 1e-6\n",
    "\n",
    "    # Early‑stop по dev (чтобы не \"разгонять\" фазу до деградации)\n",
    "    early_stop_enabled: bool = False\n",
    "    early_stop_patience_evals: int = 8\n",
    "    early_stop_warmup_evals: int = 2  # первые N eval-ов не останавливаем\n",
    "\n",
    "    # ====== Train-набор (предсэмплированный) ======\n",
    "    recreate_train: bool = False\n",
    "    train_size: int = 8000\n",
    "    train_min_difficulty: int = 1\n",
    "    train_max_difficulty: int = 10\n",
    "    train_seed: int = 2025\n",
    "\n",
    "    # ====== Curriculum по сложности ======\n",
    "    curriculum_enabled: bool = True\n",
    "    start_phase_idx: int = 0  # можно поставить 1, чтобы запускать только фазу2 (при наличии сохранённого best фазы1)\n",
    "    curriculum_phases: List[Dict[str, Any]] = field(default_factory=lambda: [\n",
    "        {\n",
    "            \"name\": \"phase1_d1-5\",\n",
    "            \"min_difficulty\": 1,\n",
    "            \"max_difficulty\": 5,\n",
    "            \"train_size\": 8000,\n",
    "            \"steps\": 200,\n",
    "            \"seed_offset\": 0,\n",
    "            \"learning_rate\": 1e-5,\n",
    "            \"kl_beta\": 0.02,\n",
    "            \"dev_eval_every_steps\": 50,\n",
    "            \"dev_eval_n\": 32,\n",
    "            \"max_completion_length\": 64,\n",
    "            # на фазе1 weights можно сместить на medium (чтобы стабилизировать базовую способность)\n",
    "            \"best_metric\": \"dev/avg\",\n",
    "            \"dev_metric_weights\": {\"easy\": 0.30, \"medium\": 0.60, \"hard\": 0.10},\n",
    "            \"early_stop_patience_evals\": 8,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"phase2_d6-10\",\n",
    "            \"min_difficulty\": 6,\n",
    "            \"max_difficulty\": 10,\n",
    "            \"train_size\": 1200,  # чуть больше данных, чтобы меньше переобучаться на \"хард\"\n",
    "            \"steps\": 400,\n",
    "            \"seed_offset\": 1,\n",
    "            \"learning_rate\": 5e-6,  # осторожнее\n",
    "            \"kl_beta\": 0.04,        # сильнее держим KL\n",
    "            \"dev_eval_every_steps\": 20,\n",
    "            \"dev_eval_n\": 32,\n",
    "            \"max_completion_length\": 32,  # LIS ответы короткие -> меньше мусора и меньше шанс рекомпиляций\n",
    "            # ВАЖНО: replay простых примеров, чтобы не было forgetting'а\n",
    "            \"replay_fraction\": 0.20,\n",
    "            \"replay_min_difficulty\": 4,\n",
    "            \"replay_max_difficulty\": 5,\n",
    "            # на фазе2 больше весим hard\n",
    "            \"best_metric\": \"dev/avg\",\n",
    "            \"dev_metric_weights\": {\"easy\": 0.20, \"medium\": 0.20, \"hard\": 0.60},\n",
    "            \"early_stop_patience_evals\": 4,\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    # ====== Unsloth / модель ======\n",
    "    max_seq_length: int = 2048\n",
    "    load_in_4bit: bool = True\n",
    "\n",
    "    # ====== LoRA ======\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: int = 16\n",
    "    lora_dropout: float = 0.0\n",
    "\n",
    "    # ====== Reward shaping ======\n",
    "    format_penalty: float = -0.1\n",
    "    distance_reward_weight: float = 0.05\n",
    "\n",
    "    # ====== GRPO ======\n",
    "    grpo_output_dir: str = \"grpo_lis_qwen2p5_1p5b\"\n",
    "\n",
    "    learning_rate: float = 1e-5\n",
    "    per_device_train_batch_size: int = 1\n",
    "    gradient_accumulation_steps: int = 8\n",
    "    num_generations: int = 8\n",
    "    max_prompt_length: int = 512\n",
    "    max_completion_length: int = 64\n",
    "\n",
    "    stop_on_answer_tag: bool = True\n",
    "    stop_string: str = \"</answer>\"\n",
    "\n",
    "    kl_beta: float = 0.02\n",
    "    logging_steps: int = 10\n",
    "    save_steps: int = 200\n",
    "    # периодические чекпоинты Trainer (для resume_from_checkpoint)\n",
    "    save_total_limit: Optional[int] = None  # None -> не удалять старые чекпоинты\n",
    "    resume_from_checkpoint: Optional[str] = None  # путь к checkpoint-* для продолжения обучения\n",
    "    max_steps: int = 800\n",
    "\n",
    "    # ====== Стабильность (убираем torch.compile, если он ломает обучение) ======\n",
    "    disable_unsloth_compile: bool = True   # UNSLOTH_COMPILE_DISABLE=1\n",
    "    disable_torch_compile: bool = True    # torch.compile -> identity\n",
    "    disable_torchdynamo: bool = True      # torch._dynamo.config.disable=True\n",
    "    torchdynamo_recompile_limit: int = 256\n",
    "\n",
    "    # ====== Чекпоинты фаз ======\n",
    "    resume_from_previous_phase_best: bool = True\n",
    "    save_phase_best: bool = True\n",
    "    phase_checkpoints_dir: str = \"results/phase_checkpoints\"\n",
    "\n",
    "    # ====== Выбор лучшей модели по dev ======\n",
    "    select_best_by_dev: bool = True\n",
    "    save_last_merged: bool = False\n",
    "    merged_model_subdir: str = \"qwen2p5_1p5b_grpo_lis_merged\"\n",
    "\n",
    "\n",
    "cfg = ExperimentConfig()\n",
    "\n",
    "# --- Применяем seed ---\n",
    "GLOBAL_SEED = cfg.global_seed\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "# --- Папки проекта ---\n",
    "DATA_DIR = Path(cfg.data_dir)\n",
    "RESULTS_DIR = Path(cfg.results_dir)\n",
    "MODELS_DIR = Path(cfg.models_dir)\n",
    "for p in [DATA_DIR, RESULTS_DIR, MODELS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_json(obj: Any, path: Path) -> None:\n",
    "    \"\"\"Утилита для сохранения JSON с нормальными отступами.\"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Сохраняем конфиг, чтобы эксперимент было проще воспроизвести\n",
    "save_json(asdict(cfg), RESULTS_DIR / \"config.json\")\n",
    "\n",
    "# Диагностика\n",
    "eff_batch = cfg.per_device_train_batch_size * cfg.gradient_accumulation_steps\n",
    "print(\"Конфиг сохранён в:\", RESULTS_DIR / \"config.json\")\n",
    "print(\"DATA_DIR    =\", DATA_DIR.resolve())\n",
    "print(\"RESULTS_DIR =\", RESULTS_DIR.resolve())\n",
    "print(\"MODELS_DIR  =\", MODELS_DIR.resolve())\n",
    "print(f\"Эффективный batch (prompts/step) = {eff_batch}  (bs={cfg.per_device_train_batch_size} * accum={cfg.gradient_accumulation_steps})\")\n",
    "print(f\"num_generations (G) = {cfg.num_generations}  -> completions/step ~ {eff_batch * cfg.num_generations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9724d4",
   "metadata": {},
   "source": [
    "### 0.2 Comet ML (логирование метрик и графиков)\n",
    "\n",
    "Если хотите видеть **графики reward / KL / accuracy / длины ответов** и сохранять артефакты эксперимента в Comet:\n",
    "\n",
    "1) Установите пакет:\n",
    "```bash\n",
    "pip install -U comet_ml\n",
    "```\n",
    "\n",
    "2) Задайте ключ (и при необходимости workspace):\n",
    "```bash\n",
    "export COMET_API_KEY=\"ВАШ_КЛЮЧ\"\n",
    "export COMET_WORKSPACE=\"ваш-workspace\"   # опционально\n",
    "```\n",
    "\n",
    "3) Включите логирование:\n",
    "```python\n",
    "cfg.comet_enabled = True\n",
    "```\n",
    "\n",
    "Если нет доступа к интернету, можно включить `cfg.comet_offline = True` (тогда логи сохранятся локально).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3bd7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/yaroslav-pankratov/ds-mag-w2-grpo/58621e6aa3854b9d8267f0cf7a15daef\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/home/yaros/DS-Mag/AI-SelectedTopics/W2-1' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMET] Experiment создан: ds-mag-w2-grpo\n"
     ]
    }
   ],
   "source": [
    "def init_comet(cfg: ExperimentConfig):\n",
    "    \"\"\"Инициализируем Comet Experiment (если включено).\n",
    "\n",
    "    Возвращает объект experiment или None (если Comet отключён/не настроен).\n",
    "    \"\"\"\n",
    "    if not cfg.comet_enabled:\n",
    "        print(\"[COMET] disabled (cfg.comet_enabled=False)\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        from comet_ml import Experiment, OfflineExperiment\n",
    "    except Exception as e:\n",
    "        print(\"[COMET] comet_ml не установлен или не импортируется:\", repr(e))\n",
    "        return None\n",
    "\n",
    "    workspace = cfg.comet_workspace or os.getenv(\"COMET_WORKSPACE\")\n",
    "    project_name = cfg.comet_project_name or os.getenv(\"COMET_PROJECT_NAME\") or \"ds-mag-w2-grpo\"\n",
    "\n",
    "    if cfg.comet_offline:\n",
    "        exp = OfflineExperiment(project_name=project_name, workspace=workspace)\n",
    "        print(\"[COMET] OfflineExperiment создан:\", project_name)\n",
    "    else:\n",
    "        api_key = \"I3UVgV6rXpj7bzgPpAH2mrTcX\"\n",
    "        if not api_key:\n",
    "            print(\"[COMET] COMET_API_KEY не задан -> Comet выключен. (export COMET_API_KEY=...)\")\n",
    "            return None\n",
    "        exp = Experiment(api_key=api_key, project_name=project_name, workspace=workspace)\n",
    "        print(\"[COMET] Experiment создан:\", project_name)\n",
    "\n",
    "    run_name = f\"{cfg.base_model.split('/')[-1]}_seed{cfg.global_seed}\"\n",
    "    try:\n",
    "        exp.set_name(run_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        exp.log_parameters(asdict(cfg))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if cfg.comet_tags:\n",
    "        try:\n",
    "            exp.add_tags(cfg.comet_tags)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Немного информации о среде\n",
    "    try:\n",
    "        import torch\n",
    "        exp.log_other(\"torch_version\", torch.__version__)\n",
    "        exp.log_other(\"torch_cuda\", str(torch.version.cuda))\n",
    "        if torch.cuda.is_available():\n",
    "            exp.log_other(\"gpu\", torch.cuda.get_device_name(0))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return exp\n",
    "\n",
    "COMET_EXPERIMENT = init_comet(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbf72f",
   "metadata": {},
   "source": [
    "## 1. Базовые интерфейсы (`Env`, `Verifier`, `Data`)\n",
    "\n",
    "Ниже — минимальные интерфейсы из спецификации ДЗ.  \n",
    "Для простоты держим их прямо в ноутбуке, но в репозитории обычно выносят в `base/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb655186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Среда/верификатор вынесены в отдельный модуль (см. lis_env.py) ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path(\".\").resolve()\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "\n",
    "from lis_env import Data, Verifier, Env, LISVerifier, LISEnv\n",
    "\n",
    "# Создаём среду\n",
    "env = LISEnv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f3ef0",
   "metadata": {},
   "source": [
    "## 2. Шаблон промпта (в отдельном файле)\n",
    "\n",
    "По условиям ДЗ нужно сделать отдельный файл с функцией, которая добавляет правила задачи **на английском**.  \n",
    "Для удобства мы создаём `prompt_templates.py` прямо из ноутбука.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864bae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_templates.py хранит правила игры/формат задания (в репозитории рядом с ноутбуком)\n",
    "from prompt_templates import build_lis_prompt\n",
    "\n",
    "# sanity-check импорта\n",
    "_ = build_lis_prompt([3, 1, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcc2a1",
   "metadata": {},
   "source": [
    "## 3. Среда: длина LIS\n",
    "\n",
    "Реализуем:\n",
    "\n",
    "- `LISEnv.generate(...)`: сэмплирует последовательности и считает *gold* длину LIS.\n",
    "- `LISVerifier.extract_answer(...)`: извлекает финальный ответ из вывода модели.\n",
    "- `LISVerifier.verify(...)`: сравнивает извлечённый ответ с *gold* ответом.\n",
    "\n",
    "Управление сложностью:\n",
    "\n",
    "- чем выше `difficulty`, тем длиннее последовательность и шире диапазон значений;\n",
    "- дополнительно отбрасываем тривиальные случаи, где LIS равна 1 или равна длине последовательности.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985984e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализация LIS-среды и верификатора находится в lis_env.py.\n",
    "# Этот ноутбук использует готовый модуль через импорт выше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1853c4",
   "metadata": {},
   "source": [
    "## 4. Быстрая проверка: генерация + верификация\n",
    "\n",
    "Быстрая проверка, что:\n",
    "\n",
    "- `generate(...)` действительно создаёт корректные задачи/ответы;\n",
    "- `extract_answer(...)` правильно достаёт число из формата `<answer>...</answer>`;\n",
    "- `verify(...)` возвращает `True` для правильного и `False` для неправильного решения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a72ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Задание 1 (сложность=3) ---\n",
      "You are given a sequence of integers.\n",
      "\n",
      "Task: compute the length of the Longest Increasing Subsequence (LIS).\n",
      "\n",
      "Definitions:\n",
      "- A subsequence is obtained by deleting zero or more elements without changing the order of remaining elements.\n",
      "- An increasing subsequence is STRICTLY increasing: each next element is > the previous one.\n",
      "\n",
      "Output requirements:\n",
      "- Return ONLY the LIS length as an integer.\n",
      "\n",
      "Sequence: [-13, -6, -12, 10, -1, -6, -11, 12, 14, 13, -13, -2]\n",
      "\n",
      "ответ: 5\n",
      "--- Задание 2 (сложность=3) ---\n",
      "You are given a sequence of integers.\n",
      "\n",
      "Task: compute the length of the Longest Increasing Subsequence (LIS).\n",
      "\n",
      "Definitions:\n",
      "- A subsequence is obtained by deleting zero or more elements without changing the order of remaining elements.\n",
      "- An increasing subsequence is STRICTLY increasing: each next element is > the previous one.\n",
      "\n",
      "Output requirements:\n",
      "- Return ONLY the LIS length as an integer.\n",
      "\n",
      "Sequence: [3, 3, -4, -4, 13, -13, -9, -10, -4, 3, -4, 8]\n",
      "\n",
      "ответ: 5\n",
      "--- Задание 3 (сложность=3) ---\n",
      "You are given a sequence of integers.\n",
      "\n",
      "Task: compute the length of the Longest Increasing Subsequence (LIS).\n",
      "\n",
      "Definitions:\n",
      "- A subsequence is obtained by deleting zero or more elements without changing the order of remaining elements.\n",
      "- An increasing subsequence is STRICTLY increasing: each next element is > the previous one.\n",
      "\n",
      "Output requirements:\n",
      "- Return ONLY the LIS length as an integer.\n",
      "\n",
      "Sequence: [-7, -9, -14, 14, -1, 10, -12, 14, 5, -2, -12, -14]\n",
      "\n",
      "ответ: 4\n",
      "\n",
      "Верификатор OK: True\n",
      "Верификатор BAD: False\n"
     ]
    }
   ],
   "source": [
    "sample = env.generate(num_of_questions=3, difficulty=3, seed=123)\n",
    "for i, d in enumerate(sample, 1):\n",
    "    print(f\"--- Задание {i} (сложность={d.difficulty}) ---\")\n",
    "    print(d.question)\n",
    "    print(\"ответ:\", d.answer)\n",
    "\n",
    "# имитируем ответ модели в требуемом формате\n",
    "fake_solution_ok = \"\"\"<think>какие-то рассуждения</think>\n",
    "<answer> {}</answer>\"\"\".format(sample[0].answer)\n",
    "\n",
    "fake_solution_bad = \"\"\"<think>...</think>\n",
    "<answer> 999</answer>\"\"\"\n",
    "\n",
    "print(\"\\nВерификатор OK:\", env.verify(sample[0], fake_solution_ok))\n",
    "print(\"Верификатор BAD:\", env.verify(sample[0], fake_solution_bad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0316b04",
   "metadata": {},
   "source": [
    "## 5. Датасеты\n",
    "\n",
    "Требования ДЗ:\n",
    "\n",
    "- **Обучающий датасет** может быть сэмплируемым/итеративным (идея: «таски приходят потоком»).\n",
    "- **Тестовые датасеты** должны быть фиксированными: генерируются один раз и дальше не меняются (для воспроизводимости).\n",
    "\n",
    "Практический момент:\n",
    "\n",
    "- В некоторых версиях `GRPOTrainer` **не поддерживает** `IterableDataset` и падает с `NotImplementedError`.\n",
    "  Поэтому мы делаем «взрослый компромисс»: используем генератор задач, но **предсэмплируем**\n",
    "  конечный train set фиксированного размера (map-style `datasets.Dataset`) и сохраняем его на диск.\n",
    "\n",
    "Сделаем:\n",
    "\n",
    "- 3 фиксированных тестовых набора: `easy / medium / hard`;\n",
    "- 1 фиксированный dev-набор (маленький) для контроля качества в процессе RL;\n",
    "- генератор задач + предсэмплинг train-набора.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbeec7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed testsets: {'easy': 200, 'medium': 200, 'hard': 200}\n",
      "Fixed devsets: {'easy': 128, 'medium': 128, 'hard': 128}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Фиксированные наборы данных на диске (test + dev)\n",
    "# -------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from w2_utils import save_jsonl, load_jsonl\n",
    "\n",
    "def make_or_load_fixed_testset(\n",
    "    env: Any,\n",
    "    n: int,\n",
    "    difficulty: int,\n",
    "    seed: int,\n",
    "    out_path: Path,\n",
    "    recreate: bool,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Создаём/загружаем фиксированный набор для eval (prompt=вопрос, answer=gold).\"\"\"\n",
    "    if out_path.exists() and (not recreate):\n",
    "        return load_jsonl(out_path)\n",
    "\n",
    "    rng = random.Random(int(seed))\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for _ in range(int(n)):\n",
    "        # sample_task есть в lis_env.Env (удобный шорткат над generate(num_of_questions=1))\n",
    "        item = env.sample_task(rng=rng, difficulty=int(difficulty))\n",
    "\n",
    "        # поддерживаем разные форматы (dict/Data)\n",
    "        if isinstance(item, dict):\n",
    "            q = item.get(\"question\") or item.get(\"prompt\") or \"\"\n",
    "            a = item.get(\"answer\") or \"\"\n",
    "        else:\n",
    "            q = getattr(item, \"question\", \"\") or getattr(item, \"prompt\", \"\")\n",
    "            a = getattr(item, \"answer\", \"\")\n",
    "\n",
    "        rows.append({\"prompt\": str(q), \"answer\": str(a)})\n",
    "\n",
    "    save_jsonl(rows, out_path)\n",
    "    return rows\n",
    "\n",
    "\n",
    "# --- test sets (для финальной оценки в infer/eval ноутбуке) ---\n",
    "fixed_testsets: Dict[str, List[Dict[str, Any]]] = {}\n",
    "for spec in cfg.test_specs:\n",
    "    p = DATA_DIR / f\"test_{spec['name']}_d{spec['difficulty']}_n{spec['n']}_seed{spec['seed']}.jsonl\"\n",
    "    fixed_testsets[spec[\"name\"]] = make_or_load_fixed_testset(\n",
    "        env=env,\n",
    "        n=int(spec[\"n\"]),\n",
    "        difficulty=int(spec[\"difficulty\"]),\n",
    "        seed=int(spec[\"seed\"]),\n",
    "        out_path=p,\n",
    "        recreate=cfg.recreate_tests,\n",
    "    )\n",
    "\n",
    "# --- dev sets (для валидации во время RL) ---\n",
    "fixed_devsets: Dict[str, List[Dict[str, Any]]] = {}\n",
    "for spec in cfg.dev_specs:\n",
    "    p = DATA_DIR / f\"dev_{spec['name']}_d{spec['difficulty']}_n{spec['n']}_seed{spec['seed']}.jsonl\"\n",
    "    fixed_devsets[spec[\"name\"]] = make_or_load_fixed_testset(\n",
    "        env=env,\n",
    "        n=int(spec[\"n\"]),\n",
    "        difficulty=int(spec[\"difficulty\"]),\n",
    "        seed=int(spec[\"seed\"]),\n",
    "        out_path=p,\n",
    "        recreate=cfg.recreate_dev,\n",
    "    )\n",
    "\n",
    "# удобный алиас на средний dev (если где-то нужен один dev)\n",
    "fixed_devset = fixed_devsets.get(\"medium\") or next(iter(fixed_devsets.values()))\n",
    "\n",
    "print(\"Fixed testsets:\", {k: len(v) for k,v in fixed_testsets.items()})\n",
    "print(\"Fixed devsets:\",  {k: len(v) for k,v in fixed_devsets.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4f447",
   "metadata": {},
   "source": [
    "### 5.1 Генератор задач и предсэмплинг train-набора\n",
    "\n",
    "Мы генерируем задачи «на лету» бесконечным генератором, но **перед обучением** берем из него `N` примеров\n",
    "и превращаем их в обычный `datasets.Dataset`.\n",
    "\n",
    "Так обучение становится:\n",
    "\n",
    "- воспроизводимым (один и тот же `seed` → один и тот же train set),\n",
    "- переносимым в репозиторий (можно хранить train.jsonl как артефакт),\n",
    "- совместимым с текущей реализацией `GRPOTrainer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d083d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 Sequence: [0, -31, 28, 6, 20, 13, -1, -4, -8, -28, -22, -13, 29, -12, -27, 32, -4, -8, 25, -1, -20, 28, 0, 16]\n",
      "8 7 Sequence: [0, 12, 4, -15, 0, -21, -28, 6, -10, 25, 28, -10, 0, 1, 2, -12, 22, -4, 24, 6, -28, 1]\n",
      "9 6 Sequence: [-3, 16, 19, 7, -11, 1, 21, -28, 32, -9, 32, 22, 27, -28, 0, -14, 14, 12, 18, 10, 7, -11, -13, 10]\n"
     ]
    }
   ],
   "source": [
    "def training_generator(env: Env, min_difficulty: int = 1, max_difficulty: int = 10, seed: int = 1234):\n",
    "    \"\"\"Бесконечный генератор задач для обучения.\n",
    "\n",
    "    Важно: GRPOTrainer в некоторых версиях НЕ поддерживает IterableDataset.\n",
    "    Поэтому на практике мы используем этот генератор, чтобы *предсэмплировать* конечный train set.\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    while True:\n",
    "        d = rng.randint(min_difficulty, max_difficulty)\n",
    "        task = env.generate(num_of_questions=1, difficulty=d, seed=rng.randint(0, 10_000_000))[0]\n",
    "        yield {\n",
    "            \"question\": task.question,\n",
    "            \"answer\": task.answer,\n",
    "            \"difficulty\": task.difficulty,\n",
    "            \"metadata\": task.metadata,\n",
    "        }\n",
    "\n",
    "def sample_train_stream(env: Env, n: int, min_difficulty: int, max_difficulty: int, seed: int):\n",
    "    \"\"\"Берём n элементов из training_generator (удобно для предсэмплинга).\"\"\"\n",
    "    gen = training_generator(env, min_difficulty=min_difficulty, max_difficulty=max_difficulty, seed=seed)\n",
    "    return [next(gen) for _ in range(n)]\n",
    "\n",
    "# Посмотрим несколько примеров\n",
    "samples = sample_train_stream(\n",
    "    env,\n",
    "    n=3,\n",
    "    min_difficulty=cfg.train_min_difficulty,\n",
    "    max_difficulty=cfg.train_max_difficulty,\n",
    "    seed=cfg.train_seed,\n",
    ")\n",
    "for s in samples:\n",
    "    print(s[\"difficulty\"], s[\"answer\"], s[\"question\"].splitlines()[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b035e92",
   "metadata": {},
   "source": [
    "## 6. System prompt и извлечение ответа\n",
    "\n",
    "По условиям ДЗ нужно использовать system prompt, который требует формат:\n",
    "\n",
    "```\n",
    "<think> ... </think>\n",
    "<answer> ... </answer>\n",
    "```\n",
    "\n",
    "Верификатор извлекает число из `<answer> ... </answer>` (запасной вариант: последнее целое число в тексте).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a316abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from w2_utils import SYSTEM_PROMPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14346f3",
   "metadata": {},
   "source": [
    "## 7. Вспомогательные функции для оценки (предпочтительно vLLM)\n",
    "\n",
    "Точность считаем как:\n",
    "\n",
    "\\[\n",
    "\\text{accuracy} = \\frac{\\#\\text{correct}}{\\#\\text{total}}\n",
    "\\]\n",
    "\n",
    "Код ниже:\n",
    "\n",
    "- собирает chat-prompts через `tokenizer.apply_chat_template(...)`;\n",
    "- делает инференс через **vLLM** (если установлен), иначе использует `transformers.generate()` как fallback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec231129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from w2_utils import build_chat_prompt, cleanup_cuda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55049806",
   "metadata": {},
   "source": [
    "## 9. GRPO-обучение с Unsloth\n",
    "\n",
    "Дальше:\n",
    "\n",
    "- загружаем базовую модель через `FastLanguageModel`;\n",
    "- подключаем LoRA-адаптеры;\n",
    "- создаём итеративный датасет промптов;\n",
    "- определяем `correctness_reward_func` как обёртку над `env.verify`;\n",
    "- обучаем через `GRPOTrainer`.\n",
    "\n",
    "> Примечание: подстройте размер батча / число шагов под ваш GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db656ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(cfg: ExperimentConfig, env, experiment=None) -> str:\n",
    "    \"\"\"\n",
    "    GRPO-обучение (curriculum по фазам) + dev-eval + сохранение best LoRA по каждой фазе и глобального best.\n",
    "\n",
    "    Ключевые идеи для стабильной фазы 2:\n",
    "      - replay простых примеров в phase2 (чтобы не было forgetting)\n",
    "      - несколько dev-срезов (easy/medium/hard) и best по взвешенному avg\n",
    "      - max_completion_length поменьше в phase2\n",
    "      - early-stop по dev (чтобы не \"дожимать\" до деградации)\n",
    "      - жёстко отключаем torch.compile/TorchDynamo, если ловите FailOnRecompileLimitHit\n",
    "    \"\"\"\n",
    "    import os, sys, shutil, math\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from typing import Any, Dict, List, Optional\n",
    "\n",
    "    experiment = experiment or globals().get(\"COMET_EXPERIMENT\", None)\n",
    "\n",
    "    # -------------------------\n",
    "    # 0) Стабилизация (до импорта unsloth)\n",
    "    # -------------------------\n",
    "    if cfg.disable_unsloth_compile:\n",
    "        os.environ[\"UNSLOTH_COMPILE_DISABLE\"] = \"1\"\n",
    "    # ВАЖНО: fullgraph=False (иначе шанс FailOnRecompileLimitHit гораздо выше)\n",
    "    os.environ[\"UNSLOTH_FULLGRAPH\"] = \"0\"\n",
    "    os.environ[\"UNSLOTH_COMPILE_IGNORE_ERRORS\"] = \"1\"\n",
    "\n",
    "    if cfg.disable_torchdynamo:\n",
    "        os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
    "    if cfg.disable_torch_compile:\n",
    "        os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"\n",
    "\n",
    "    # Снести автосгенерённый кэш Unsloth (чтобы не подхватить старые артефакты)\n",
    "    shutil.rmtree(Path.cwd() / \"unsloth_compiled_cache\", ignore_errors=True)\n",
    "\n",
    "    # Runtime-переключатели (на случай если torch уже импортировали раньше)\n",
    "    try:\n",
    "        import torch._dynamo\n",
    "        if cfg.disable_torchdynamo:\n",
    "            torch._dynamo.config.disable = True\n",
    "        torch._dynamo.config.suppress_errors = True\n",
    "        if hasattr(torch._dynamo.config, \"recompile_limit\"):\n",
    "            torch._dynamo.config.recompile_limit = int(cfg.torchdynamo_recompile_limit)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if cfg.disable_torch_compile and hasattr(torch, \"compile\"):\n",
    "        import torch\n",
    "\n",
    "        def _noop_torch_compile(fn=None, *args, **kwargs):\n",
    "            # Вариант 1: torch.compile(fn, ...)\n",
    "            if callable(fn):\n",
    "                return fn\n",
    "            # Вариант 2: torch.compile(...)-> decorator\n",
    "            def _decorator(f):\n",
    "                return f\n",
    "            return _decorator\n",
    "\n",
    "        # Патчим\n",
    "        torch.compile = _noop_torch_compile\n",
    "\n",
    "    # Если Unsloth уже был импортирован ДО установки env, лучше перезапустить kernel\n",
    "    if \"unsloth\" in sys.modules:\n",
    "        print(\"[WARN] `unsloth` уже импортирован в этом kernel'е. \"\n",
    "              \"Переменные среды UNSLOTH_* могли НЕ примениться. \"\n",
    "              \"Если ловите FailOnRecompileLimitHit — сделайте Restart Kernel и Run All.\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Импортируем нужное для обучения\n",
    "    # -------------------------\n",
    "    from unsloth import FastLanguageModel\n",
    "    from trl import GRPOConfig, GRPOTrainer\n",
    "    from datasets import Dataset\n",
    "    import inspect\n",
    "    import re\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Dev-наборы: готовим заранее (фиксация + воспроизводимость)\n",
    "    # -------------------------\n",
    "    def _dev_path(spec: Dict[str, Any]) -> Path:\n",
    "        return DATA_DIR / f\"dev_{spec['name']}_d{spec['difficulty']}_n{spec['n']}_seed{spec['seed']}.jsonl\"\n",
    "\n",
    "    dev_sets: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for spec in cfg.dev_specs:\n",
    "        name = str(spec[\"name\"])\n",
    "        path = _dev_path(spec)\n",
    "        ds = make_or_load_fixed_testset(\n",
    "            env=env,\n",
    "            out_path=path,\n",
    "            n=int(spec[\"n\"]),\n",
    "            difficulty=int(spec[\"difficulty\"]),\n",
    "            seed=int(spec[\"seed\"]),\n",
    "            recreate=cfg.recreate_dev,\n",
    "        )\n",
    "        dev_sets[name] = ds\n",
    "\n",
    "    for name, rows in dev_sets.items():\n",
    "        for r in rows:\n",
    "            if \"prompt\" not in r or not r[\"prompt\"]:\n",
    "                q = r.get(\"question\")\n",
    "                if q is None:\n",
    "                    continue\n",
    "                r[\"prompt\"] = q  # именно сырой question; chat prompt строим позже через build_chat_prompt\n",
    "\n",
    "    # Детерминированные индексы для quick dev-eval\n",
    "    dev_quick_indices: Dict[str, List[int]] = {}\n",
    "    for spec in cfg.dev_specs:\n",
    "        name = str(spec[\"name\"])\n",
    "        n = len(dev_sets[name])\n",
    "        k = min(cfg.dev_eval_n, n)\n",
    "        rng = random.Random(cfg.global_seed + 999 + int(spec[\"seed\"]))\n",
    "        dev_quick_indices[name] = rng.sample(range(n), k)\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Загружаем базовую модель + LoRA\n",
    "    # -------------------------\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=cfg.base_model,\n",
    "        max_seq_length=cfg.max_seq_length,\n",
    "        dtype=None,\n",
    "        load_in_4bit=cfg.load_in_4bit,\n",
    "        use_gradient_checkpointing=False,  # стабильнее\n",
    "    )\n",
    "\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=cfg.lora_r,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                        \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        lora_alpha=cfg.lora_alpha,\n",
    "        lora_dropout=cfg.lora_dropout,\n",
    "        bias=\"none\",\n",
    "        use_gradient_checkpointing=False,\n",
    "        random_state=cfg.global_seed,\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Reward functions (correctness + format penalty + distance shaping)\n",
    "    # -------------------------\n",
    "    def _trim_to_stop(text: str, stop_string: str) -> str:\n",
    "        if not stop_string:\n",
    "            return text\n",
    "        idx = text.find(stop_string)\n",
    "        if idx == -1:\n",
    "            return text\n",
    "        return text[: idx + len(stop_string)]\n",
    "\n",
    "    _ANS_RE = re.compile(r\"<answer>\\s*([-+]?\\d+)\\s*</answer>\", flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def _extract_int_from_answer(text: str) -> Optional[int]:\n",
    "        m = _ANS_RE.search(text)\n",
    "        if not m:\n",
    "            return None\n",
    "        try:\n",
    "            return int(m.group(1))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # --- Reward functions ---\n",
    "    # TRL/GRPO может передавать gold-ответы под разными ключами (answer/answers/labels...),\n",
    "    # поэтому делаем функцию-адаптер, чтобы не ловить TypeError/KeyError.\n",
    "    _VERIFY_NARGS = None\n",
    "    try:\n",
    "        _VERIFY_NARGS = len(inspect.signature(env.verify).parameters)\n",
    "    except Exception:\n",
    "        _VERIFY_NARGS = None\n",
    "\n",
    "    def _verify(prompt: str, completion: str, answer: str) -> bool:\n",
    "        \"\"\"Совместимость с разными реализациями env.verify:\n",
    "        - env.verify(prompt, completion, answer)\n",
    "        - env.verify(Data(...), completion)  (как в этом ноутбуке)\n",
    "        \"\"\"\n",
    "        if _VERIFY_NARGS == 3:\n",
    "            return bool(env.verify(prompt, completion, answer))\n",
    "        return bool(env.verify(Data(question=str(prompt), answer=str(answer)), completion))\n",
    "\n",
    "    def _get_answers(answers, kwargs, n: int):\n",
    "        if answers is not None:\n",
    "            return answers\n",
    "        for k in (\"answers\", \"answer\", \"labels\", \"label\", \"solutions\", \"solution\"):\n",
    "            if k in kwargs and kwargs[k] is not None:\n",
    "                return kwargs[k]\n",
    "        return [\"\"] * int(n)\n",
    "\n",
    "    def correctness_reward_func(prompts, completions, answers=None, **kwargs):\n",
    "        answers = _get_answers(answers, kwargs, len(completions))\n",
    "        out = []\n",
    "        for p, c, a in zip(prompts, completions, answers):\n",
    "            c_use = _trim_to_stop(c, cfg.stop_string) if cfg.stop_on_answer_tag else c\n",
    "            ok = _verify(str(p), str(c_use), str(a))\n",
    "            out.append(1.0 if ok else 0.0)\n",
    "        return out\n",
    "\n",
    "    def format_penalty_reward_func(prompts, completions, answers=None, **kwargs):\n",
    "        # answers не нужны, но оставляем аргумент для совместимости\n",
    "        out = []\n",
    "        for c in completions:\n",
    "            c_use = _trim_to_stop(c, cfg.stop_string) if cfg.stop_on_answer_tag else c\n",
    "            pred = _extract_int_from_answer(c_use)\n",
    "            out.append(0.0 if pred is not None else float(cfg.format_penalty))\n",
    "        return out\n",
    "\n",
    "    def distance_reward_func(prompts, completions, answers=None, **kwargs):\n",
    "        answers = _get_answers(answers, kwargs, len(completions))\n",
    "        w = float(cfg.distance_reward_weight)\n",
    "        if w <= 0:\n",
    "            return [0.0 for _ in completions]\n",
    "        out = []\n",
    "        for c, a in zip(completions, answers):\n",
    "            c_use = _trim_to_stop(c, cfg.stop_string) if cfg.stop_on_answer_tag else c\n",
    "            pred = _extract_int_from_answer(c_use)\n",
    "            try:\n",
    "                gold = int(a)\n",
    "            except Exception:\n",
    "                gold = None\n",
    "            if pred is None or gold is None:\n",
    "                out.append(0.0)\n",
    "                continue\n",
    "            dist = abs(int(pred) - int(gold))\n",
    "            out.append(w * math.exp(-dist))\n",
    "        return out\n",
    "\n",
    "    reward_funcs = [correctness_reward_func, format_penalty_reward_func]\n",
    "    if cfg.distance_reward_weight > 0:\n",
    "        reward_funcs.append(distance_reward_func)\n",
    "\n",
    "    # -------------------------\n",
    "    # 5) Dev-eval helpers\n",
    "    # -------------------------\n",
    "    def _gen_kwargs(max_new_tokens: int, temperature: float):\n",
    "        d = dict(\n",
    "            max_new_tokens=int(max_new_tokens),\n",
    "            do_sample=(temperature > 0),\n",
    "        )\n",
    "        if temperature and temperature > 0:\n",
    "            d[\"temperature\"] = float(temperature)\n",
    "        return d\n",
    "\n",
    "    def _eval_on_subset(dataset_rows: List[Dict[str, Any]], indices: List[int]) -> float:\n",
    "        correct = 0\n",
    "        total = len(indices)\n",
    "\n",
    "        # Unsloth: быстрее в inference\n",
    "        try:\n",
    "            if hasattr(model, \"for_inference\"):\n",
    "                model.for_inference()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        for i in indices:\n",
    "            ex = dataset_rows[i]\n",
    "            user_prompt = ex[\"prompt\"]\n",
    "            gold = ex[\"answer\"]\n",
    "\n",
    "            prompt_text = build_chat_prompt(tokenizer, user_prompt)\n",
    "            inputs = tokenizer(\n",
    "                prompt_text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=cfg.max_prompt_length,\n",
    "            ).to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.generate(**inputs, **_gen_kwargs(cfg.dev_max_new_tokens, cfg.dev_temperature))\n",
    "\n",
    "            gen_ids = out[0][inputs[\"input_ids\"].shape[1]:]\n",
    "            completion = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "            if cfg.stop_on_answer_tag:\n",
    "                completion = _trim_to_stop(completion, cfg.stop_string)\n",
    "\n",
    "            if _verify(user_prompt, completion, gold):\n",
    "                correct += 1\n",
    "\n",
    "        # обратно в training режим\n",
    "        try:\n",
    "            if hasattr(model, \"for_training\"):\n",
    "                model.for_training()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return correct / max(total, 1)\n",
    "\n",
    "    def _eval_full(dataset_rows: List[Dict[str, Any]]) -> float:\n",
    "        return _eval_on_subset(dataset_rows, list(range(len(dataset_rows))))\n",
    "\n",
    "    def _compute_primary_metric(accs: Dict[str, float], best_metric: str, weights: Dict[str, float]) -> float:\n",
    "        if best_metric.startswith(\"dev/\") and best_metric != \"dev/avg\":\n",
    "            key = best_metric.split(\"/\", 1)[1]\n",
    "            return float(accs.get(key, 0.0))\n",
    "        # weighted avg\n",
    "        num = 0.0\n",
    "        den = 0.0\n",
    "        for k, w in (weights or {}).items():\n",
    "            if k in accs:\n",
    "                num += float(w) * float(accs[k])\n",
    "                den += float(w)\n",
    "        if den <= 0:\n",
    "            return float(np.mean(list(accs.values()))) if accs else 0.0\n",
    "        return num / den\n",
    "\n",
    "    def _capture_lora_state_to_cpu() -> Dict[str, torch.Tensor]:\n",
    "        st = {}\n",
    "        for n, p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                st[n] = p.detach().cpu()\n",
    "        return st\n",
    "\n",
    "    # -------------------------\n",
    "    # 6) Curriculum phases\n",
    "    # -------------------------\n",
    "    if cfg.curriculum_enabled and cfg.curriculum_phases:\n",
    "        phases = cfg.curriculum_phases\n",
    "    else:\n",
    "        phases = [{\n",
    "            \"name\": \"single\",\n",
    "            \"min_difficulty\": cfg.train_min_difficulty,\n",
    "            \"max_difficulty\": cfg.train_max_difficulty,\n",
    "            \"train_size\": cfg.train_size,\n",
    "            \"steps\": cfg.max_steps,\n",
    "            \"seed_offset\": 0,\n",
    "            \"learning_rate\": cfg.learning_rate,\n",
    "            \"kl_beta\": cfg.kl_beta,\n",
    "            \"dev_eval_every_steps\": cfg.dev_eval_every_steps,\n",
    "            \"dev_eval_n\": cfg.dev_eval_n,\n",
    "            \"max_completion_length\": cfg.max_completion_length,\n",
    "        }]\n",
    "\n",
    "    start_phase_idx = int(getattr(cfg, \"start_phase_idx\", 0) or 0)\n",
    "    start_phase_idx = max(0, min(start_phase_idx, len(phases)-1))\n",
    "\n",
    "    # глобальный best (по выбранной dev-метрике)\n",
    "    best = {\n",
    "        \"score\": -1.0,\n",
    "        \"accs\": None,\n",
    "        \"step\": None,\n",
    "        \"phase\": None,\n",
    "        \"lora_state\": None,\n",
    "    }\n",
    "\n",
    "    phase_ckpt_dir = Path(cfg.phase_checkpoints_dir)\n",
    "    phase_ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # 7) Семплинг trainset под фазу (+ replay)\n",
    "    # -------------------------\n",
    "    def _train_path(phase_name: str, min_d: int, max_d: int, n: int, seed: int) -> Path:\n",
    "        return DATA_DIR / f\"train_{phase_name}_d{min_d}-{max_d}_n{n}_seed{seed}.jsonl\"\n",
    "\n",
    "    def _sample_rows(n: int, min_d: int, max_d: int, seed: int) -> List[Dict[str, Any]]:\n",
    "        gen = training_generator(env, min_difficulty=min_d, max_difficulty=max_d, seed=seed)\n",
    "        rows = []\n",
    "        for _ in range(n):\n",
    "            item = next(gen)\n",
    "            q = item.get(\"question\") or item.get(\"prompt\") or \"\"\n",
    "            a = item.get(\"answer\") or \"\"\n",
    "            rows.append({\"prompt\": build_chat_prompt(tokenizer, str(q)), \"answer\": str(a)})\n",
    "        return rows\n",
    "\n",
    "    def _make_or_load_phase_trainset(phase: Dict[str, Any]) -> Dataset:\n",
    "        phase_name = str(phase[\"name\"])\n",
    "        min_d = int(phase[\"min_difficulty\"])\n",
    "        max_d = int(phase[\"max_difficulty\"])\n",
    "        n = int(phase.get(\"train_size\", cfg.train_size))\n",
    "        seed = int(cfg.train_seed + 1337 * int(phase.get(\"seed_offset\", 0)))\n",
    "\n",
    "        path = _train_path(phase_name, min_d, max_d, n, seed)\n",
    "\n",
    "        # если нужен replay — делаем датасет \"main + replay\", потом shuffle\n",
    "        replay_frac = float(phase.get(\"replay_fraction\", 0.0) or 0.0)\n",
    "        replay_min = int(phase.get(\"replay_min_difficulty\", cfg.train_min_difficulty))\n",
    "        replay_max = int(phase.get(\"replay_max_difficulty\", min_d - 1)) if phase.get(\"replay_max_difficulty\") is None else int(phase.get(\"replay_max_difficulty\", min_d - 1))\n",
    "\n",
    "        # IMPORTANT: чтобы кэш trainset не переиспользовался при смене replay_*,\n",
    "        # добавляем replay-параметры в имя файла.\n",
    "        if replay_frac > 0 and replay_min <= replay_max:\n",
    "            rp = int(round(replay_frac * 100))\n",
    "            path = path.with_name(f\"{path.stem}_replay{rp}_d{replay_min}-{replay_max}{path.suffix}\")\n",
    "\n",
    "\n",
    "        if path.exists() and (not cfg.recreate_train) and (not phase.get(\"recreate_train\", False)):\n",
    "            rows = load_jsonl(path)\n",
    "            return Dataset.from_list(rows)\n",
    "\n",
    "        if replay_frac > 0 and replay_min <= replay_max:\n",
    "            n_replay = int(round(n * replay_frac))\n",
    "            n_main = max(0, n - n_replay)\n",
    "\n",
    "            rows_main = _sample_rows(n_main, min_d, max_d, seed=seed)\n",
    "            rows_replay = _sample_rows(n_replay, replay_min, replay_max, seed=seed + 424242)\n",
    "\n",
    "            rows = rows_main + rows_replay\n",
    "            rng = random.Random(seed + 777)\n",
    "            rng.shuffle(rows)\n",
    "        else:\n",
    "            rows = _sample_rows(n, min_d, max_d, seed=seed)\n",
    "\n",
    "        save_jsonl(rows, path)\n",
    "        return Dataset.from_list(rows)\n",
    "\n",
    "    # -------------------------\n",
    "    # 8) Dev-eval callback (+ early stop) + phase-best\n",
    "    # -------------------------\n",
    "    from transformers import TrainerCallback\n",
    "\n",
    "    class DevEvalCallback(TrainerCallback):\n",
    "        def __init__(self, phase: Dict[str, Any], global_step_offset: int):\n",
    "            self.phase = phase\n",
    "            self.global_step_offset = global_step_offset\n",
    "\n",
    "            self.phase_name = str(phase[\"name\"])\n",
    "            self.best_metric = str(phase.get(\"best_metric\", cfg.best_metric))\n",
    "            self.weights = dict(phase.get(\"dev_metric_weights\", cfg.dev_metric_weights) or {})\n",
    "\n",
    "            self.eval_every = int(phase.get(\"dev_eval_every_steps\", cfg.dev_eval_every_steps))\n",
    "            self.quick_k = int(phase.get(\"dev_eval_n\", cfg.dev_eval_n))\n",
    "\n",
    "            # early stop params\n",
    "            self.early_stop_enabled = bool(cfg.early_stop_enabled and phase.get(\"early_stop_enabled\", True))\n",
    "            self.patience = int(phase.get(\"early_stop_patience_evals\", cfg.early_stop_patience_evals))\n",
    "            self.warmup = int(phase.get(\"early_stop_warmup_evals\", cfg.early_stop_warmup_evals))\n",
    "            self.min_delta = float(phase.get(\"best_min_delta\", cfg.best_min_delta))\n",
    "\n",
    "            self.eval_calls = 0\n",
    "            self.no_improve = 0\n",
    "            self.best_seen = -1.0\n",
    "\n",
    "            # phase-best\n",
    "            self.phase_best_score = -1.0\n",
    "            self.phase_best_step_abs = None\n",
    "            self.phase_best_accs = None\n",
    "            self.phase_best_lora_state = None\n",
    "\n",
    "        def on_step_end(self, args, state, control, **kwargs):\n",
    "            nonlocal best\n",
    "\n",
    "            local_step = int(state.global_step)\n",
    "            if local_step <= 0:\n",
    "                return control\n",
    "            if (local_step % self.eval_every) != 0:\n",
    "                return control\n",
    "\n",
    "            self.eval_calls += 1\n",
    "            abs_step = self.global_step_offset + local_step\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # КЛЮЧ: во 2-й фазе всегда считаем FULL (без quick)\n",
    "            # Можно переопределить явно: self.force_full_eval = True\n",
    "            # ------------------------------------------------------------\n",
    "            force_full_eval = bool(getattr(self, \"force_full_eval\", False)) or str(self.phase_name).startswith(\"phase2\")\n",
    "\n",
    "            # 1) Вычисляем accs + primary\n",
    "            if force_full_eval:\n",
    "                # FULL по всем devset'ам\n",
    "                accs = {name: _eval_full(dev_sets[name]) for name in dev_sets.keys()}\n",
    "                primary = _compute_primary_metric(accs, self.best_metric, self.weights)\n",
    "\n",
    "                nice = \" | \".join([f\"{k}={accs[k]:.4f}\" for k in sorted(accs.keys())])\n",
    "                # n для каждого devset (обычно одинаковое, но пусть будет явно)\n",
    "                n_info = \", \".join([f\"{k}:{len(dev_sets[k])}\" for k in sorted(dev_sets.keys())])\n",
    "                print(f\"[DEV-FULL  @ step {abs_step} | {self.phase_name}] {nice} | {self.best_metric}={primary:.4f} (n={n_info})\")\n",
    "\n",
    "                if experiment is not None:\n",
    "                    try:\n",
    "                        experiment.log_metric(f\"dev_full/{self.phase_name}/{self.best_metric}\", float(primary), step=abs_step)\n",
    "                        for k, v in accs.items():\n",
    "                            experiment.log_metric(f\"dev_full/{self.phase_name}/{k}\", float(v), step=abs_step)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            else:\n",
    "                # QUICK (как было раньше) — для фаз, где хотим экономить время\n",
    "                accs = {}\n",
    "                for spec in cfg.dev_specs:\n",
    "                    name = str(spec[\"name\"])\n",
    "                    idxs = dev_quick_indices[name][: self.quick_k]\n",
    "                    accs[name] = _eval_on_subset(dev_sets[name], idxs)\n",
    "\n",
    "                primary = _compute_primary_metric(accs, self.best_metric, self.weights)\n",
    "\n",
    "                nice = \" | \".join([f\"{k}={accs[k]:.4f}\" for k in sorted(accs.keys())])\n",
    "                print(f\"[DEV-QUICK @ step {abs_step} | {self.phase_name}] {nice} | {self.best_metric}={primary:.4f} (n={self.quick_k} each)\")\n",
    "\n",
    "                if experiment is not None:\n",
    "                    try:\n",
    "                        experiment.log_metric(f\"dev_quick/{self.phase_name}/{self.best_metric}\", float(primary), step=abs_step)\n",
    "                        for k, v in accs.items():\n",
    "                            experiment.log_metric(f\"dev_quick/{self.phase_name}/{k}\", float(v), step=abs_step)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            # 2) Phase-best (для resume/перехода между фазами) — теперь:\n",
    "            #    - в фазе2 будет по FULL (потому что primary = FULL)\n",
    "            if primary > (self.phase_best_score + self.min_delta):\n",
    "                self.phase_best_score = float(primary)\n",
    "                self.phase_best_step_abs = int(abs_step)\n",
    "                self.phase_best_accs = dict(accs)\n",
    "                self.phase_best_lora_state = _capture_lora_state_to_cpu()\n",
    "\n",
    "                if getattr(cfg, \"save_phase_best\", True):\n",
    "                    phase_ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    phase_best_path = phase_ckpt_dir / f\"{phase_name}_best_lora.pt\"\n",
    "                    torch.save(self.phase_best_lora_state, phase_best_path)\n",
    "\n",
    "                    phase_best_meta = {\n",
    "                        \"phase\": phase_name,\n",
    "                        \"score\": float(self.phase_best_score),\n",
    "                        \"step_abs\": int(self.phase_best_step_abs),\n",
    "                        \"step_phase\": int(state.global_step),\n",
    "                        \"checkpoint_dir\": str(Path(args.output_dir) / f\"checkpoint-{state.global_step}\"),\n",
    "                        \"accs\": {k: float(v) for k, v in self.phase_best_accs.items()},\n",
    "                        \"lora_path\": str(phase_best_path),\n",
    "                    }\n",
    "                    save_json(phase_best_meta, phase_ckpt_dir / f\"{phase_name}_best_meta.json\")\n",
    "\n",
    "                # сохранить полноценный trainer checkpoint (optimizer/scheduler/state)\n",
    "                control.should_save = True\n",
    "\n",
    "            # 3) Global-best\n",
    "            def _maybe_update_global(score: float, accs_full: Dict[str, float]):\n",
    "                nonlocal best\n",
    "                if score > (best[\"score\"] + self.min_delta):\n",
    "                    print(f\"[BEST] {self.best_metric}={score:.4f} @ step={abs_step} (phase={self.phase_name})\")\n",
    "                    best[\"score\"] = float(score)\n",
    "                    best[\"accs\"] = dict(accs_full)\n",
    "                    best[\"step\"] = int(abs_step)\n",
    "                    best[\"phase\"] = self.phase_name\n",
    "                    best[\"lora_state\"] = _capture_lora_state_to_cpu()\n",
    "\n",
    "            if cfg.select_best_by_dev and (primary > (best[\"score\"] + self.min_delta)):\n",
    "                if force_full_eval:\n",
    "                    # уже FULL — подтверждать не нужно\n",
    "                    _maybe_update_global(primary, accs)\n",
    "                else:\n",
    "                    # прежняя логика: quick → при улучшении можно подтвердить full\n",
    "                    if cfg.dev_full_eval_on_best:\n",
    "                        full_accs = {name: _eval_full(dev_sets[name]) for name in dev_sets.keys()}\n",
    "                        full_primary = _compute_primary_metric(full_accs, self.best_metric, self.weights)\n",
    "                        nice2 = \" | \".join([f\"{k}={full_accs[k]:.4f}\" for k in sorted(full_accs.keys())])\n",
    "                        print(f\"[DEV-FULL  @ step {abs_step} | {self.phase_name}] {nice2} | {self.best_metric}={full_primary:.4f}\")\n",
    "\n",
    "                        if experiment is not None:\n",
    "                            try:\n",
    "                                experiment.log_metric(f\"dev_full/{self.phase_name}/{self.best_metric}\", float(full_primary), step=abs_step)\n",
    "                                for k, v in full_accs.items():\n",
    "                                    experiment.log_metric(f\"dev_full/{self.phase_name}/{k}\", float(v), step=abs_step)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "\n",
    "                        _maybe_update_global(full_primary, full_accs)\n",
    "                    else:\n",
    "                        _maybe_update_global(primary, accs)\n",
    "\n",
    "            # 4) Early stop — базируемся на primary (во 2-й фазе это FULL)\n",
    "            improved = primary > (self.best_seen + self.min_delta)\n",
    "            if improved:\n",
    "                self.best_seen = float(primary)\n",
    "                self.no_improve = 0\n",
    "            else:\n",
    "                self.no_improve += 1\n",
    "\n",
    "            if self.early_stop_enabled and (self.eval_calls > self.warmup):\n",
    "                if self.no_improve >= self.patience:\n",
    "                    print(\n",
    "                        f\"[EARLY-STOP] phase={self.phase_name}: no improvement for {self.no_improve} evals \"\n",
    "                        f\"(patience={self.patience}). Stopping training for this phase.\"\n",
    "                    )\n",
    "                    control.should_training_stop = True\n",
    "\n",
    "            return control\n",
    "\n",
    "    # -------------------------\n",
    "    # 9) Тренировка по фазам\n",
    "    # -------------------------\n",
    "    global_step_offset = 0\n",
    "\n",
    "    for phase_idx in range(start_phase_idx, len(phases)):\n",
    "        phase = phases[phase_idx]\n",
    "        phase_name = str(phase[\"name\"])\n",
    "        print(f\"\\n=== START {phase_name} (phase_idx={phase_idx}) ===\")\n",
    "\n",
    "        # 9.1) Если стартуем не с первой фазы — пробуем загрузить best предыдущей фазы\n",
    "        if cfg.resume_from_previous_phase_best and phase_idx > 0:\n",
    "            prev_name = str(phases[phase_idx - 1][\"name\"])\n",
    "            prev_best_path = phase_ckpt_dir / f\"{prev_name}_best_lora.pt\"\n",
    "            if prev_best_path.exists():\n",
    "                try:\n",
    "                    state = torch.load(prev_best_path, map_location=\"cpu\")\n",
    "                    model.load_state_dict(state, strict=False)\n",
    "                    print(f\"[RESUME] Loaded previous phase best LoRA: {prev_best_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[RESUME] Failed to load {prev_best_path}: {repr(e)}\")\n",
    "            else:\n",
    "                if phase_idx == start_phase_idx and start_phase_idx > 0:\n",
    "                    raise FileNotFoundError(\n",
    "                        f\"start_phase_idx={start_phase_idx}, но нет файла {prev_best_path}. \"\n",
    "                        f\"Либо запусти фазу1 (start_phase_idx=0), либо положи чекпоинт фазы1.\"\n",
    "                    )\n",
    "\n",
    "        # 9.2) Trainset под фазу\n",
    "        train_ds = _make_or_load_phase_trainset(phase)\n",
    "\n",
    "        # 9.3) Гиперпараметры фазы\n",
    "        lr = float(phase.get(\"learning_rate\", cfg.learning_rate))\n",
    "        beta = float(phase.get(\"kl_beta\", cfg.kl_beta))\n",
    "        max_steps = int(phase.get(\"steps\", cfg.max_steps))\n",
    "        max_comp = int(phase.get(\"max_completion_length\", cfg.max_completion_length))\n",
    "\n",
    "        # 9.4) GRPOConfig с аккуратным \"best-effort\" для разных версий trl\n",
    "        def _grpo_extra_args():\n",
    "            extra = {}\n",
    "            sig = inspect.signature(GRPOConfig.__init__)\n",
    "            params = sig.parameters\n",
    "\n",
    "            # stop sequences / stop strings (если поддерживается)\n",
    "            for key in [\"stop_strings\", \"stop_sequences\", \"stop_sequence\", \"stop\"]:\n",
    "                if key in params and cfg.stop_on_answer_tag and cfg.stop_string:\n",
    "                    extra[key] = [cfg.stop_string] if (\"strings\" in key or \"sequences\" in key) else cfg.stop_string\n",
    "\n",
    "            # иногда параметр называется \"beta\" или \"kl_beta\" — trl версии разные\n",
    "            if \"beta\" in params:\n",
    "                extra[\"beta\"] = beta\n",
    "            if \"kl_beta\" in params:\n",
    "                extra[\"kl_beta\"] = beta\n",
    "\n",
    "            return extra\n",
    "\n",
    "        grpo_args = GRPOConfig(\n",
    "            output_dir=str(RESULTS_DIR / cfg.grpo_output_dir / phase_name),\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=cfg.per_device_train_batch_size,\n",
    "            gradient_accumulation_steps=cfg.gradient_accumulation_steps,\n",
    "            num_generations=cfg.num_generations,\n",
    "            max_prompt_length=cfg.max_prompt_length,\n",
    "            max_completion_length=max_comp,\n",
    "            logging_steps=cfg.logging_steps,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=cfg.save_steps,\n",
    "            save_total_limit=getattr(cfg, \"save_total_limit\", None),\n",
    "            max_steps=max_steps,\n",
    "            **_grpo_extra_args(),\n",
    "        )\n",
    "\n",
    "        # 9.5) Trainer\n",
    "        callback = DevEvalCallback(phase=phase, global_step_offset=global_step_offset)\n",
    "\n",
    "        trainer = GRPOTrainer(\n",
    "            model=model,\n",
    "            args=grpo_args,\n",
    "            train_dataset=train_ds,\n",
    "            reward_funcs=reward_funcs,\n",
    "            callbacks=[callback],\n",
    "        )\n",
    "\n",
    "        # 9.6) train (можно продолжать с чекпоинта)\n",
    "        resume_ckpt = phase.get(\"resume_from_checkpoint\", None) or getattr(cfg, \"resume_from_checkpoint\", None)\n",
    "        trainer.train(resume_from_checkpoint=resume_ckpt)\n",
    "        print(f\"=== END {phase_name} ===\\n\")\n",
    "\n",
    "        # 9.7) сохранить BEST LoRA текущей фазы (именно лучшую точку внутри фазы)\n",
    "        if cfg.save_phase_best:\n",
    "            phase_best_path = phase_ckpt_dir / f\"{phase_name}_best_lora.pt\"\n",
    "            state_to_save = callback.phase_best_lora_state or _capture_lora_state_to_cpu()\n",
    "            torch.save(state_to_save, phase_best_path)\n",
    "            print(f\"[SAVED] Phase best LoRA -> {phase_best_path} (best_score={callback.phase_best_score:.4f}, step={callback.phase_best_step_abs})\")\n",
    "\n",
    "        global_step_offset += int(trainer.state.global_step)\n",
    "\n",
    "        # чистим память\n",
    "        try:\n",
    "            cleanup_cuda()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # -------------------------\n",
    "    # 10) Применяем глобальный best LoRA и сохраняем merged модель\n",
    "    # -------------------------\n",
    "    if best.get(\"lora_state\") is not None:\n",
    "        model.load_state_dict(best[\"lora_state\"], strict=False)\n",
    "        print(f\"[LOAD] Applied GLOBAL best LoRA from phase={best.get('phase')} step={best.get('step')} score={best.get('score'):.4f}\")\n",
    "\n",
    "    merged_dir = MODELS_DIR / cfg.merged_model_subdir\n",
    "    merged_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model.save_pretrained_merged(str(merged_dir), tokenizer, save_method=\"merged_16bit\")\n",
    "    tokenizer.save_pretrained(str(merged_dir))\n",
    "\n",
    "    # best содержит тензоры (LoRA state) -> для JSON сохраняем только метаданные\n",
    "    best_meta = {k: v for k, v in best.items() if k != \"lora_state\"}\n",
    "    if isinstance(best_meta.get(\"score\"), (int, float)):\n",
    "        best_meta[\"score\"] = float(best_meta[\"score\"])\n",
    "    if isinstance(best_meta.get(\"step\"), (int, float)):\n",
    "        best_meta[\"step\"] = int(best_meta[\"step\"])\n",
    "    if isinstance(best_meta.get(\"accs\"), dict):\n",
    "        best_meta[\"accs\"] = {k: float(v) for k, v in best_meta[\"accs\"].items()}\n",
    "    save_json(best_meta, RESULTS_DIR / \"best_model_by_dev.json\")\n",
    "\n",
    "    print(\"[DONE] merged model saved to:\", merged_dir.resolve())\n",
    "    return str(merged_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63cd2d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.11.1: Fast Qwen2 patching. Transformers: 4.57.2.\n",
      "   \\\\   /|    NVIDIA RTX PRO 6000 Blackwell Workstation Edition. Num GPUs = 1. Max memory: 95.592 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.35. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.11.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== START phase1_d1-5 (phase_idx=0) ===\n",
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 8,000 | Num Epochs = 1 | Total steps = 200\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,562,179,072 (1.18% trained)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m String value length exceeds 1000 characters and will be truncated. Provided value: 'LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping={'base_model_class': 'Qwen2ForCausalLM', 'parent_library': 'transformers.models.qwen2.modeling_qwen2', 'unsloth_fixed': True}, peft_version='0.18.1', base_model_name_or_path='unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit', revision=None, inference_mode=False, r=16, target_modules={'o_proj', 'k_proj', 'down_proj', 'q_proj', 'up_proj', 'v_proj', 'gate_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, alora_invocation_tokens=None, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, arrow_config=None, ensure_weight_tying=False)'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 20:04, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / correctness_reward_func / mean</th>\n",
       "      <th>rewards / correctness_reward_func / std</th>\n",
       "      <th>rewards / format_penalty_reward_func / mean</th>\n",
       "      <th>rewards / format_penalty_reward_func / std</th>\n",
       "      <th>rewards / distance_reward_func / mean</th>\n",
       "      <th>rewards / distance_reward_func / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044623</td>\n",
       "      <td>0.246385</td>\n",
       "      <td>40.929688</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.535937</td>\n",
       "      <td>14.378618</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>55.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.297771</td>\n",
       "      <td>-0.064063</td>\n",
       "      <td>0.048062</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.012173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>0.188831</td>\n",
       "      <td>41.721875</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>13.803588</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>52.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.236161</td>\n",
       "      <td>-0.063906</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.011927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.071617</td>\n",
       "      <td>0.251008</td>\n",
       "      <td>30.567187</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>12.461327</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>53.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.085375</td>\n",
       "      <td>0.107813</td>\n",
       "      <td>0.264135</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>0.013418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.136414</td>\n",
       "      <td>0.305708</td>\n",
       "      <td>19.428125</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>10.170739</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.241382</td>\n",
       "      <td>0.146875</td>\n",
       "      <td>0.351412</td>\n",
       "      <td>-0.023750</td>\n",
       "      <td>0.042723</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.015972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.217163</td>\n",
       "      <td>0.345684</td>\n",
       "      <td>14.201562</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.076563</td>\n",
       "      <td>10.076723</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>41.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.329124</td>\n",
       "      <td>0.209375</td>\n",
       "      <td>0.404953</td>\n",
       "      <td>-0.010469</td>\n",
       "      <td>0.029757</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.317380</td>\n",
       "      <td>0.363969</td>\n",
       "      <td>12.443750</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>10.085685</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.392845</td>\n",
       "      <td>0.298438</td>\n",
       "      <td>0.456220</td>\n",
       "      <td>-0.004531</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.018222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.250942</td>\n",
       "      <td>0.286177</td>\n",
       "      <td>11.051562</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>9.520852</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.409528</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.419797</td>\n",
       "      <td>-0.004531</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.016836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.338971</td>\n",
       "      <td>0.325714</td>\n",
       "      <td>10.425000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>9.490553</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.544996</td>\n",
       "      <td>0.317188</td>\n",
       "      <td>0.450067</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.015779</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.017444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.312782</td>\n",
       "      <td>0.356410</td>\n",
       "      <td>11.195312</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>56.900000</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>9.663995</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.406645</td>\n",
       "      <td>0.292187</td>\n",
       "      <td>0.450081</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>0.017123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.422402</td>\n",
       "      <td>0.402324</td>\n",
       "      <td>10.403125</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>43.700000</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>9.469310</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.831954</td>\n",
       "      <td>0.396875</td>\n",
       "      <td>0.483838</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.011264</td>\n",
       "      <td>0.027871</td>\n",
       "      <td>0.018250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.328803</td>\n",
       "      <td>0.324309</td>\n",
       "      <td>10.479688</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>55.700000</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>9.453512</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.626582</td>\n",
       "      <td>0.306250</td>\n",
       "      <td>0.444488</td>\n",
       "      <td>-0.002188</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>0.016928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.358041</td>\n",
       "      <td>0.338222</td>\n",
       "      <td>10.181250</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>9.499597</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.768666</td>\n",
       "      <td>0.332813</td>\n",
       "      <td>0.464081</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>0.026322</td>\n",
       "      <td>0.017102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.305708</td>\n",
       "      <td>0.308919</td>\n",
       "      <td>9.979688</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>49.900000</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>9.723710</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.531367</td>\n",
       "      <td>0.282813</td>\n",
       "      <td>0.429652</td>\n",
       "      <td>-0.000938</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.016392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.347375</td>\n",
       "      <td>0.370356</td>\n",
       "      <td>10.204688</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>9.439330</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.803241</td>\n",
       "      <td>0.323437</td>\n",
       "      <td>0.458586</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.017239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.360506</td>\n",
       "      <td>10.445312</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>9.247926</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.583077</td>\n",
       "      <td>0.318750</td>\n",
       "      <td>0.454578</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.013078</td>\n",
       "      <td>0.025471</td>\n",
       "      <td>0.017117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.373012</td>\n",
       "      <td>0.339940</td>\n",
       "      <td>10.370313</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>54.200000</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>9.689704</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.534694</td>\n",
       "      <td>0.348438</td>\n",
       "      <td>0.470507</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.017892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.332648</td>\n",
       "      <td>0.332642</td>\n",
       "      <td>10.245313</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>9.391094</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.598528</td>\n",
       "      <td>0.309375</td>\n",
       "      <td>0.454389</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>0.017181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.371261</td>\n",
       "      <td>0.368026</td>\n",
       "      <td>10.614062</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>57.300000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>9.767189</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>38.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.477435</td>\n",
       "      <td>0.346875</td>\n",
       "      <td>0.462668</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.026730</td>\n",
       "      <td>0.017139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.374395</td>\n",
       "      <td>0.329254</td>\n",
       "      <td>9.775000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>9.435155</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.792110</td>\n",
       "      <td>0.348438</td>\n",
       "      <td>0.458116</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.027207</td>\n",
       "      <td>0.016642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.347638</td>\n",
       "      <td>0.316789</td>\n",
       "      <td>10.431250</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>52.100000</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>9.408867</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.449988</td>\n",
       "      <td>0.323437</td>\n",
       "      <td>0.464691</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.017378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEV-QUICK @ step 50 | phase1_d1-5] easy=0.3438 | hard=0.2500 | medium=0.4062 | dev/avg=0.3719 (n=32 each)\n",
      "[DEV-FULL  @ step 50 | phase1_d1-5] easy=0.4141 | hard=0.2109 | medium=0.3750 | dev/avg=0.3703\n",
      "[BEST] dev/avg=0.3703 @ step=50 (phase=phase1_d1-5)\n",
      "[DEV-QUICK @ step 100 | phase1_d1-5] easy=0.3750 | hard=0.2188 | medium=0.4062 | dev/avg=0.3781 (n=32 each)\n",
      "[DEV-FULL  @ step 100 | phase1_d1-5] easy=0.4453 | hard=0.1719 | medium=0.3828 | dev/avg=0.3805\n",
      "[BEST] dev/avg=0.3805 @ step=100 (phase=phase1_d1-5)\n",
      "[DEV-QUICK @ step 150 | phase1_d1-5] easy=0.4062 | hard=0.2188 | medium=0.4062 | dev/avg=0.3875 (n=32 each)\n",
      "[DEV-FULL  @ step 150 | phase1_d1-5] easy=0.4297 | hard=0.1719 | medium=0.3906 | dev/avg=0.3805\n",
      "[DEV-QUICK @ step 200 | phase1_d1-5] easy=0.4062 | hard=0.1875 | medium=0.4062 | dev/avg=0.3844 (n=32 each)\n",
      "[DEV-FULL  @ step 200 | phase1_d1-5] easy=0.4297 | hard=0.1797 | medium=0.3906 | dev/avg=0.3813\n",
      "[BEST] dev/avg=0.3813 @ step=200 (phase=phase1_d1-5)\n",
      "=== END phase1_d1-5 ===\n",
      "\n",
      "[SAVED] Phase best LoRA -> results/phase_checkpoints/phase1_d1-5_best_lora.pt (best_score=0.3875, step=150)\n",
      "\n",
      "=== START phase2_d6-10 (phase_idx=1) ===\n",
      "[RESUME] Loaded previous phase best LoRA: results/phase_checkpoints/phase1_d1-5_best_lora.pt\n",
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,200 | Num Epochs = 3 | Total steps = 400\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 8 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,562,179,072 (1.18% trained)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m String value length exceeds 1000 characters and will be truncated. Provided value: 'LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping={'base_model_class': 'Qwen2ForCausalLM', 'parent_library': 'transformers.models.qwen2.modeling_qwen2', 'unsloth_fixed': True}, peft_version='0.18.1', base_model_name_or_path='unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit', revision=None, inference_mode=False, r=16, target_modules={'o_proj', 'k_proj', 'down_proj', 'q_proj', 'up_proj', 'v_proj', 'gate_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, alora_invocation_tokens=None, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, arrow_config=None, ensure_weight_tying=False)'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 50:12, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / correctness_reward_func / mean</th>\n",
       "      <th>rewards / correctness_reward_func / std</th>\n",
       "      <th>rewards / format_penalty_reward_func / mean</th>\n",
       "      <th>rewards / format_penalty_reward_func / std</th>\n",
       "      <th>rewards / distance_reward_func / mean</th>\n",
       "      <th>rewards / distance_reward_func / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.201928</td>\n",
       "      <td>0.338382</td>\n",
       "      <td>9.878125</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>9.127437</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735969</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.387626</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.016627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.250204</td>\n",
       "      <td>0.380073</td>\n",
       "      <td>9.715625</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>9.144029</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.762550</td>\n",
       "      <td>0.232813</td>\n",
       "      <td>0.420580</td>\n",
       "      <td>-0.002656</td>\n",
       "      <td>0.015195</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>0.017626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.204727</td>\n",
       "      <td>0.289937</td>\n",
       "      <td>9.684375</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>9.294421</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.781280</td>\n",
       "      <td>0.190625</td>\n",
       "      <td>0.383082</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.017110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.193353</td>\n",
       "      <td>0.309401</td>\n",
       "      <td>10.123437</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>9.271534</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.658378</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.377377</td>\n",
       "      <td>-0.004063</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>0.016980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.212232</td>\n",
       "      <td>0.299021</td>\n",
       "      <td>10.403125</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>9.305560</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.649771</td>\n",
       "      <td>0.198437</td>\n",
       "      <td>0.386958</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.016919</td>\n",
       "      <td>0.017103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.183110</td>\n",
       "      <td>0.294504</td>\n",
       "      <td>9.835938</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>0.026562</td>\n",
       "      <td>9.230465</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.665356</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.365454</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.016860</td>\n",
       "      <td>0.016033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.306299</td>\n",
       "      <td>9.887500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>9.174820</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.727588</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.393722</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.018571</td>\n",
       "      <td>0.016926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.233151</td>\n",
       "      <td>0.311322</td>\n",
       "      <td>9.903125</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>9.189749</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>0.215625</td>\n",
       "      <td>0.404927</td>\n",
       "      <td>-0.002031</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.016831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>0.322058</td>\n",
       "      <td>10.010938</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.029687</td>\n",
       "      <td>9.336117</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.640717</td>\n",
       "      <td>0.207813</td>\n",
       "      <td>0.397582</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.014965</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>0.017462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.194227</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>9.984375</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>9.202085</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.600830</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.379271</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.017352</td>\n",
       "      <td>0.016509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.246045</td>\n",
       "      <td>0.307534</td>\n",
       "      <td>10.118750</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>9.231445</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.680809</td>\n",
       "      <td>0.229687</td>\n",
       "      <td>0.412207</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.017791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.228838</td>\n",
       "      <td>0.305536</td>\n",
       "      <td>10.154687</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>9.226877</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.616749</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.397894</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.018838</td>\n",
       "      <td>0.016854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.206605</td>\n",
       "      <td>0.282640</td>\n",
       "      <td>10.467187</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>9.333288</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.559659</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>0.377680</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>0.016477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.196838</td>\n",
       "      <td>0.271821</td>\n",
       "      <td>10.103125</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>9.249439</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.587288</td>\n",
       "      <td>0.182812</td>\n",
       "      <td>0.378516</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>0.016739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.190614</td>\n",
       "      <td>0.295315</td>\n",
       "      <td>10.234375</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>9.312666</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.512197</td>\n",
       "      <td>0.176563</td>\n",
       "      <td>0.368696</td>\n",
       "      <td>-0.003438</td>\n",
       "      <td>0.017648</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.016072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.218343</td>\n",
       "      <td>0.297841</td>\n",
       "      <td>10.135938</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>9.356800</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.578926</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.401520</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>0.017586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.295412</td>\n",
       "      <td>10.620313</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>9.270185</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.489178</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.402777</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>0.017322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.207777</td>\n",
       "      <td>0.266056</td>\n",
       "      <td>10.523438</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>9.396417</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.519667</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>0.380541</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>0.016315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.227836</td>\n",
       "      <td>0.263337</td>\n",
       "      <td>10.495313</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.057813</td>\n",
       "      <td>9.176432</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.540103</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.399943</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.018461</td>\n",
       "      <td>0.017149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.241945</td>\n",
       "      <td>0.284001</td>\n",
       "      <td>10.098437</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>9.171482</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.458863</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.413287</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>0.017395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.258278</td>\n",
       "      <td>0.330287</td>\n",
       "      <td>10.431250</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>9.224962</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.528491</td>\n",
       "      <td>0.240625</td>\n",
       "      <td>0.418115</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.019997</td>\n",
       "      <td>0.017609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.216343</td>\n",
       "      <td>0.256355</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>9.226731</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.501175</td>\n",
       "      <td>0.201563</td>\n",
       "      <td>0.391048</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>0.016758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.233957</td>\n",
       "      <td>0.313088</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>9.359158</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.428849</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.399170</td>\n",
       "      <td>-0.004219</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.019426</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.253812</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>10.693750</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>9.422964</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.464643</td>\n",
       "      <td>0.239063</td>\n",
       "      <td>0.412757</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>0.018030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.198797</td>\n",
       "      <td>0.262038</td>\n",
       "      <td>10.765625</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.060937</td>\n",
       "      <td>9.388319</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.474831</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.376227</td>\n",
       "      <td>-0.003438</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>0.016252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.242770</td>\n",
       "      <td>0.255365</td>\n",
       "      <td>10.826562</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>9.266020</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.479263</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.412313</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>0.017483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.213180</td>\n",
       "      <td>11.654687</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>9.360754</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.484346</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.346373</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.015252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.268454</td>\n",
       "      <td>0.277217</td>\n",
       "      <td>11.398438</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>9.461889</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.503604</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.420003</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>0.017428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.273936</td>\n",
       "      <td>0.296493</td>\n",
       "      <td>11.117188</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>9.270360</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.470821</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.427181</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.021280</td>\n",
       "      <td>0.017739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.233734</td>\n",
       "      <td>0.301931</td>\n",
       "      <td>11.485938</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.092188</td>\n",
       "      <td>9.402686</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.624770</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.404984</td>\n",
       "      <td>-0.003750</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.018734</td>\n",
       "      <td>0.017431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.193780</td>\n",
       "      <td>0.236604</td>\n",
       "      <td>10.873437</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>0.067187</td>\n",
       "      <td>9.348114</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.670905</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.375473</td>\n",
       "      <td>-0.002656</td>\n",
       "      <td>0.013719</td>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.016597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.250645</td>\n",
       "      <td>0.229872</td>\n",
       "      <td>10.854688</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>9.295451</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.537630</td>\n",
       "      <td>0.232813</td>\n",
       "      <td>0.384230</td>\n",
       "      <td>-0.002188</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.016911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.220856</td>\n",
       "      <td>0.243341</td>\n",
       "      <td>10.446875</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>9.198965</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.541276</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.397867</td>\n",
       "      <td>-0.002656</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.018825</td>\n",
       "      <td>0.016588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.255008</td>\n",
       "      <td>0.307204</td>\n",
       "      <td>10.564063</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>9.322561</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.532945</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.411981</td>\n",
       "      <td>-0.002188</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>0.017467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.272403</td>\n",
       "      <td>0.278565</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>30.300000</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>9.276201</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.611417</td>\n",
       "      <td>0.254688</td>\n",
       "      <td>0.433174</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.015779</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>0.018232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.221527</td>\n",
       "      <td>0.239106</td>\n",
       "      <td>10.859375</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>9.222322</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.543227</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.390760</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.016857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.213898</td>\n",
       "      <td>0.257160</td>\n",
       "      <td>10.985938</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>9.282592</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.525292</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.390874</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.017237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.218560</td>\n",
       "      <td>0.246705</td>\n",
       "      <td>10.467187</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>9.226534</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.597549</td>\n",
       "      <td>0.201563</td>\n",
       "      <td>0.387128</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.016432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.210973</td>\n",
       "      <td>0.223670</td>\n",
       "      <td>11.271875</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>9.364133</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.529724</td>\n",
       "      <td>0.196875</td>\n",
       "      <td>0.356561</td>\n",
       "      <td>-0.003438</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.016052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.230957</td>\n",
       "      <td>0.277643</td>\n",
       "      <td>10.935937</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>9.340197</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.534175</td>\n",
       "      <td>0.215625</td>\n",
       "      <td>0.406707</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.017673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEV-FULL  @ step 220 | phase2_d6-10] easy=0.4375 | hard=0.2422 | medium=0.3906 | dev/avg=0.3109 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 240 | phase2_d6-10] easy=0.4375 | hard=0.3047 | medium=0.4062 | dev/avg=0.3516 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 260 | phase2_d6-10] easy=0.4453 | hard=0.3438 | medium=0.3672 | dev/avg=0.3688 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 280 | phase2_d6-10] easy=0.4297 | hard=0.3516 | medium=0.3438 | dev/avg=0.3656 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 300 | phase2_d6-10] easy=0.4375 | hard=0.3047 | medium=0.3203 | dev/avg=0.3344 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 320 | phase2_d6-10] easy=0.4375 | hard=0.3203 | medium=0.3203 | dev/avg=0.3438 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 340 | phase2_d6-10] easy=0.4375 | hard=0.3047 | medium=0.3359 | dev/avg=0.3375 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 360 | phase2_d6-10] easy=0.4219 | hard=0.3047 | medium=0.2734 | dev/avg=0.3219 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 380 | phase2_d6-10] easy=0.4297 | hard=0.3281 | medium=0.2969 | dev/avg=0.3422 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 400 | phase2_d6-10] easy=0.4375 | hard=0.3203 | medium=0.2969 | dev/avg=0.3391 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 420 | phase2_d6-10] easy=0.4453 | hard=0.3281 | medium=0.3516 | dev/avg=0.3562 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 440 | phase2_d6-10] easy=0.4219 | hard=0.3203 | medium=0.2812 | dev/avg=0.3328 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 460 | phase2_d6-10] easy=0.4297 | hard=0.3125 | medium=0.3281 | dev/avg=0.3391 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 480 | phase2_d6-10] easy=0.4531 | hard=0.3203 | medium=0.3359 | dev/avg=0.3500 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 500 | phase2_d6-10] easy=0.4453 | hard=0.3281 | medium=0.3359 | dev/avg=0.3531 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 520 | phase2_d6-10] easy=0.4219 | hard=0.3203 | medium=0.3438 | dev/avg=0.3453 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 540 | phase2_d6-10] easy=0.4297 | hard=0.3281 | medium=0.3359 | dev/avg=0.3500 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 560 | phase2_d6-10] easy=0.4297 | hard=0.2969 | medium=0.3203 | dev/avg=0.3281 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 580 | phase2_d6-10] easy=0.4297 | hard=0.3281 | medium=0.3359 | dev/avg=0.3500 (n=easy:128, hard:128, medium:128)\n",
      "[DEV-FULL  @ step 600 | phase2_d6-10] easy=0.4219 | hard=0.3281 | medium=0.3203 | dev/avg=0.3453 (n=easy:128, hard:128, medium:128)\n",
      "=== END phase2_d6-10 ===\n",
      "\n",
      "[SAVED] Phase best LoRA -> results/phase_checkpoints/phase2_d6-10_best_lora.pt (best_score=0.3688, step=260)\n",
      "[LOAD] Applied GLOBAL best LoRA from phase=phase1_d1-5 step=200 score=0.3813\n",
      "Found HuggingFace hub cache directory: /home/yaros/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|██████████| 1/1 [00:00<00:00, 3366.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/home/yaros/DS-Mag/AI-SelectedTopics/W2-1/models/qwen2p5_1p5b_grpo_lis_merged`\n",
      "[DONE] merged model saved to: /home/yaros/DS-Mag/AI-SelectedTopics/W2-1/models/qwen2p5_1p5b_grpo_lis_merged\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/qwen2p5_1p5b_grpo_lis_merged'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запуск GRPO-обучения (может занять время; на Colab/Kaggle нужен GPU)\n",
    "TRAINED_MODEL_DIR = run_train(cfg, env)\n",
    "\n",
    "# Для удобства: сохраняем путь к модели как артефакт эксперимента\n",
    "save_json({\"trained_model_dir\": TRAINED_MODEL_DIR}, RESULTS_DIR / \"trained_model.json\")\n",
    "\n",
    "TRAINED_MODEL_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e4642-4831-4513-8af3-c9cfa4c6510e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Дальше: инференс и финальная оценка\n",
    "\n",
    "1) Активируйте **eval‑среду** (отдельный env) с `vllm` и `transformers`.\n",
    "\n",
    "2) Откройте ноутбук **`week2_grpo_lis_infer_eval.ipynb`**.\n",
    "\n",
    "Он автоматически:\n",
    "- загрузит `results/config.json` (если он существует),\n",
    "- загрузит путь к модели из `results/trained_model.json`,\n",
    "- посчитает accuracy на фиксированных `data/test_*.jsonl`,\n",
    "- построит график baseline vs trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d81e9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : Qwen2.5-1.5B-Instruct_seed42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/yaroslav-pankratov/ds-mag-w2-grpo/58621e6aa3854b9d8267f0cf7a15daef\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase1_d1-5/dev/avg [4]                   : (0.37031250000000004, 0.38125000000000003)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase1_d1-5/easy [4]                      : (0.4140625, 0.4453125)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase1_d1-5/hard [4]                      : (0.171875, 0.2109375)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase1_d1-5/medium [4]                    : (0.375, 0.390625)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase2_d6-10/dev/avg [20]                 : (0.3109375, 0.36875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase2_d6-10/easy [20]                    : (0.421875, 0.453125)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase2_d6-10/hard [20]                    : (0.2421875, 0.3515625)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full/phase2_d6-10/medium [20]                  : (0.2734375, 0.40625)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_quick/phase1_d1-5/dev/avg [4]                  : (0.37187500000000007, 0.3875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_quick/phase1_d1-5/easy [4]                     : (0.34375, 0.40625)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_quick/phase1_d1-5/hard [4]                     : (0.1875, 0.25)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_quick/phase1_d1-5/medium                       : 0.40625\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [480]                                         : (-0.10183119773864746, 0.08417598903179169)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completion_length [60]                       : (23.4, 64.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/clipped_ratio [60]               : (0.0046875, 0.55625)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/max_length [60]                  : (23.4, 64.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/max_terminated_length [60]       : (12.1, 55.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/mean_length [60]                 : (9.684375, 41.721875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/mean_terminated_length [60]      : (9.127437305450439, 14.378618431091308)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/min_length [60]                  : (2.2, 9.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/completions/min_terminated_length [60]       : (2.2, 9.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/epoch [62]                                   : (0.01, 2.6666666666666665)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/frac_reward_zero_std [60]                    : (0.0, 0.0875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/grad_norm [60]                               : (0.08398205786943436, 1.6378594636917114)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/kl [60]                                      : (0.0017570935844560154, 0.831954450532794)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/learning_rate [60]                           : (1.388888888888889e-08, 9.5e-06)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [60]                                    : (0.0, 0.0313)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/num_tokens [60]                              : (128459.0, 5220935.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/reward [60]                                  : (0.011978404875844718, 0.4224021196365356)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/reward_std [60]                              : (0.1888313189148903, 0.40232352912425995)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rewards/correctness_reward_func/mean [60]    : (0.0703125, 0.396875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rewards/correctness_reward_func/std [60]     : (0.23616144955158233, 0.48383780717849734)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rewards/distance_reward_func/mean [60]       : (0.005560392141342163, 0.027870882116258145)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rewards/distance_reward_func/std [60]        : (0.011926900316029786, 0.018250259570777416)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rewards/format_penalty_reward_func/mean [60] : (-0.06406250149011612, -0.0009375000139698386)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/rewards/format_penalty_reward_func/std [60]  : (0.006753681600093842, 0.049347701296210286)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/total_flos                                   : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_loss [2]                               : (0.00941574943717569, 0.023030361868441106)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_runtime [2]                            : (1209.6849, 3017.0615)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_samples_per_second [2]                 : (8.485, 10.581)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_steps_per_second [2]                   : (0.133, 0.165)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name            : Qwen2.5-1.5B-Instruct_seed42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gpu             : NVIDIA RTX PRO 6000 Blackwell Workstation Edition\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_cuda      : 12.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torch_version   : 2.10.0+cu128\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|dispatch_batches                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|even_batches                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|gradient_accumulation_kwargs        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|non_blocking                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|split_batches                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|use_seedable_sampler                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adafactor                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta1                                             : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta2                                             : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_epsilon                                           : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|auto_find_batch_size                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|average_tokens_across_devices                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|batch_eval_metrics                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|beta                                                   : 0.04\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16                                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16_full_eval                                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|cache_implementation                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|data_seed                                              : 3407\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_drop_last                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_num_workers                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_persistent_workers                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_pin_memory                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_prefetch_factor                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_backend                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_broadcast_buffers                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_bucket_cap_mb                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_find_unused_parameters                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_timeout                                            : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|debug                                                  : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|deepspeed                                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|delta                                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_dropout                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_tqdm                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_eval                                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_predict                                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_train                                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ds3_gather_for_generation                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|epsilon                                                : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|epsilon_high                                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_accumulation_steps                                : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_delay                                             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_do_concat_batches                                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_on_start                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_steps                                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_strategy                                          : no\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_use_gather_object                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16                                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_backend                                           : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_full_eval                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_opt_level                                         : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp                                                   : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|min_num_params                             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_grad_ckpt                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_v2                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_min_num_params                                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_transformer_layer_cls_to_wrap                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|full_determinism                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|generation_batch_size                                  : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|generation_kwargs                                      : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_accumulation_steps                            : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing                                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing_kwargs                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|greater_is_better                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|group_by_length                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|half_precision_backend                                 : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_always_push                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_model_id                                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_private_repo                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_revision                                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_strategy                                           : every_save\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_token                                              : <HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ignore_data_skip                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|importance_sampling_level                              : token\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_for_metrics                                    : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_inputs_for_metrics                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_num_input_tokens_seen                          : no\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_tokens_per_second                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|jit_mode_eval                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_names                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_smoothing_factor                                 : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|learning_rate                                          : 5e-06\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|length_column_name                                     : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|liger_kernel_config                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|load_best_model_at_end                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|local_rank                                             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_completions                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level                                              : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level_replica                                      : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_on_each_node                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_dir                                            : results/grpo_lis_qwen2p5_1p5b/phase2_d6-10/runs/Feb28_14-49-19_ML5090\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_first_step                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_nan_inf_filter                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_steps                                          : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_strategy                                       : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|loss_type                                              : bnpo\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_kwargs                                    : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_type                                      : linear\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mask_truncated_completions                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_completion_length                                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_grad_norm                                          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_prompt_length                                      : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_steps                                              : 400\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|metric_for_best_model                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|min_p                                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|model_init_kwargs                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mp_parameters                                          : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|neftune_noise_alpha                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|no_cuda                                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_completions_to_print                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_generations                                        : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_iterations                                         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_train_epochs                                       : 3.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim                                                  : adamw_8bit\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_args                                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_target_modules                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|output_dir                                             : results/grpo_lis_qwen2p5_1p5b/phase2_d6-10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|overwrite_output_dir                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|parallelism_config                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|past_index                                             : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_eval_batch_size                             : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_train_batch_size                            : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_eval_batch_size                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_train_batch_size                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|prediction_loss_only                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|project                                                : huggingface\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_model_id                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_organization                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_token                                      : <PUSH_TO_HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ray_scope                                              : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ref_model_mixup_alpha                                  : 0.6\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ref_model_sync_steps                                   : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|remove_unused_columns                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|repetition_penalty                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|report_to                                              : ['comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|restore_callback_states_from_checkpoint                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|resume_from_checkpoint                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|reward_weights                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|run_name                                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_on_each_node                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_only_model                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_safetensors                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_steps                                             : 200\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_strategy                                          : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_total_limit                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|scale_rewards                                          : group\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|seed                                                   : 3407\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|shuffle_dataset                                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|skip_memory_metrics                                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|steps_per_generation                                   : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|sync_ref_model                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|temperature                                            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tf32                                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|top_entropy_quantile                                   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|top_k                                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|top_p                                                  : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_backend                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_mode                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_empty_cache_steps                                : 250\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torchdynamo                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_metrics_debug                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_num_cores                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|trackio_space_id                                       : trackio\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|unsloth_num_chunks                                     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_cpu                                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_legacy_prediction_loop                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_liger_kernel                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_liger_loss                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_mps_device                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_transformers_paged                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_vllm                                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_enable_sleep_mode                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_gpu_memory_utilization                            : 0.3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_guided_decoding_regex                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_importance_sampling_cap                           : 2.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_importance_sampling_correction                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_mode                                              : colocate\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_model_impl                                        : vllm\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_sampling_params                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_server_base_url                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_server_host                                       : 0.0.0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_server_port                                       : 8000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_server_timeout                                    : 240.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|vllm_tensor_parallel_size                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|wandb_log_unique_prompts                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_ratio                                           : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_steps                                           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|weight_decay                                           : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     base_model                                                  : Qwen/Qwen2.5-1.5B-Instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     best_metric                                                 : dev/avg\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     best_min_delta                                              : 1e-06\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_enabled                                               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_offline                                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_project_name                                          : ds-mag-w2-grpo\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_tags                                                  : ['W2', 'GRPO', 'LIS']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_workspace                                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_name_or_path                                        : unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|add_cross_attention                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|architectures                                        : ['Qwen2ForCausalLM']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|attention_dropout                                    : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bad_words_ids                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|begin_suppress_tokens                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bos_token_id                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|chunk_size_feed_forward                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|cross_attention_hidden_size                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|decoder_start_token_id                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|diversity_penalty                                    : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|do_sample                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|dtype                                                : bfloat16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|early_stopping                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|encoder_no_repeat_ngram_size                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|eos_token_id                                         : 151645\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|exponential_decay_length_penalty                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|finetuning_task                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_bos_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_eos_token_id                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_act                                           : silu\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|hidden_size                                          : 1536\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|0                                           : LABEL_0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|1                                           : LABEL_1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|initializer_range                                    : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|intermediate_size                                    : 8960\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_decoder                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_encoder_decoder                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_0                                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_1                                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|layer_types                                          : ['full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention', 'full_attention']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|length_penalty                                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_length                                           : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_position_embeddings                              : 32768\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_window_layers                                    : 21\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|min_length                                           : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|model_type                                           : qwen2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|no_repeat_ngram_size                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_attention_heads                                  : 12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beam_groups                                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beams                                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_hidden_layers                                    : 28\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_key_value_heads                                  : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_return_sequences                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_attentions                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_hidden_states                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_scores                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pad_token_id                                         : 151654\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|prefix                                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|problem_type                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pruned_heads                                         : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|bnb_4bit_compute_dtype           : bfloat16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|bnb_4bit_quant_type              : nf4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|bnb_4bit_use_double_quant        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|llm_int8_enable_fp32_cpu_offload : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|llm_int8_has_fp16_weight         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|llm_int8_skip_modules            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|llm_int8_threshold               : 6.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|load_in_4bit                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|load_in_8bit                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|quantization_config|quant_method                     : bitsandbytes\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|remove_invalid_values                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|repetition_penalty                                   : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict                                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict_in_generate                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|rms_norm_eps                                         : 1e-06\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|rope_scaling                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|rope_theta                                           : 1000000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sep_token_id                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sliding_window                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|suppress_tokens                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|temperature                                          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tf_legacy_loss                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_encoder_decoder                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_word_embeddings                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tokenizer_class                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_k                                                : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_p                                                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torchscript                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|transformers_version                                 : 4.57.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|typical_p                                            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|unsloth_fixed                                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|unsloth_version                                      : 2025.11.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_bfloat16                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_cache                                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_sliding_window                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|vocab_size                                           : 151936\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     curriculum_enabled                                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     curriculum_phases                                           : [{'name': 'phase1_d1-5', 'min_difficulty': 1, 'max_difficulty': 5, 'train_size': 8000, 'steps': 200, 'seed_offset': 0, 'learning_rate': 1e-05, 'kl_beta': 0.02, 'dev_eval_every_steps': 50, 'dev_eval_n': 32, 'max_completion_length': 64, 'best_metric': 'dev/avg', 'dev_metric_weights': {'easy': 0.3, 'medium': 0.6, 'hard': 0.1}, 'early_stop_patience_evals': 8}, {'name': 'phase2_d6-10', 'min_difficulty': 6, 'max_difficulty': 10, 'train_size': 1200, 'steps': 400, 'seed_offset': 1, 'learning_rate': 5e-06, 'kl_beta': 0.04, 'dev_eval_every_steps': 20, 'dev_eval_n': 32, 'max_completion_length': 32, 'replay_fraction': 0.2, 'replay_min_difficulty': 4, 'replay_max_difficulty': 5, 'best_metric': 'dev/avg', 'dev_metric_weights': {'easy': 0.2, 'medium': 0.2, 'hard': 0.6}, 'early_stop_patience_evals': 4}]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data_dir                                                    : data\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_eval_every_steps                                        : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_eval_n                                                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_full_eval_on_best                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_max_new_tokens                                          : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_metric_weights|easy                                     : 0.25\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_metric_weights|hard                                     : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_metric_weights|medium                                   : 0.25\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_specs                                                   : [{'name': 'easy', 'difficulty': 2, 'n': 128, 'seed': 4001}, {'name': 'medium', 'difficulty': 5, 'n': 128, 'seed': 4002}, {'name': 'hard', 'difficulty': 8, 'n': 128, 'seed': 4003}]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dev_temperature                                             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disable_torch_compile                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disable_torchdynamo                                         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     disable_unsloth_compile                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     distance_reward_weight                                      : 0.05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     early_stop_enabled                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     early_stop_patience_evals                                   : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     early_stop_warmup_evals                                     : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format_penalty                                              : -0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     global_seed                                                 : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gradient_accumulation_steps                                 : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grpo_output_dir                                             : grpo_lis_qwen2p5_1p5b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kl_beta                                                     : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate                                               : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     load_in_4bit                                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     logging_steps                                               : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lora_alpha                                                  : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lora_dropout                                                : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lora_r                                                      : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_completion_length                                       : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_prompt_length                                           : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_seq_length                                              : 2048\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_steps                                                   : 800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     merged_model_subdir                                         : qwen2p5_1p5b_grpo_lis_merged\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     models_dir                                                  : models\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_generations                                             : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     peft_config|default                                         : LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping={'base_model_class': 'Qwen2ForCausalLM', 'parent_library': 'transformers.models.qwen2.modeling_qwen2', 'unsloth_fixed': True}, peft_version='0.18.1', base_model_name_or_path='unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit', revision=None, inference_mode=False, r=16, target_modules={'o_proj', 'k_proj', 'down_proj', 'q_proj', 'up_proj', 'v_proj', 'gate_proj'}, exclude_modules=None, lora_alpha=16, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, alora_invocation_tokens=None, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemera [truncated]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_train_batch_size                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     phase_checkpoints_dir                                       : results/phase_checkpoints\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     recreate_dev                                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     recreate_tests                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     recreate_train                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     results_dir                                                 : results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume_from_checkpoint                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume_from_previous_phase_best                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_last_merged                                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_phase_best                                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_steps                                                  : 200\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_total_limit                                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     select_best_by_dev                                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     start_phase_idx                                             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stop_on_answer_tag                                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stop_string                                                 : </answer>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_specs                                                  : [{'name': 'easy', 'difficulty': 2, 'n': 200, 'seed': 1001}, {'name': 'medium', 'difficulty': 5, 'n': 200, 'seed': 2001}, {'name': 'hard', 'difficulty': 8, 'n': 200, 'seed': 3001}]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     torchdynamo_recompile_limit                                 : 256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_max_difficulty                                        : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_min_difficulty                                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_seed                                                  : 2025\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_size                                                  : 8000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMET] Experiment ended.\n"
     ]
    }
   ],
   "source": [
    "# (опционально) Завершить эксперимент Comet, чтобы гарантированно \"дослать\" логи.\n",
    "# В интерактивной работе можно не вызывать end() — Comet обычно сам всё отправит при завершении ядра.\n",
    "if globals().get(\"COMET_EXPERIMENT\", None) is not None:\n",
    "    try:\n",
    "        COMET_EXPERIMENT.end()\n",
    "        print(\"[COMET] Experiment ended.\")\n",
    "    except Exception as e:\n",
    "        print(\"[COMET] end() failed:\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds-mag-ai-sel-top-w2-1-train)",
   "language": "python",
   "name": "ds-mag-ai-sel-top-w2-1-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
